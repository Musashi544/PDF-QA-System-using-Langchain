{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwogHGlkmc-Y",
        "outputId": "4844902f-fba5-404f-ccbe-56c9e7c8403d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "# Download and run the Ollama Linux install script\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add in Secrets in colab \n",
        "<br>\n",
        "1. NGROK_AUTH_TOKEN - Auth token got from ngrok\n",
        "2. DOMAIN - Domain got from ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0Aw4K9Em4YA"
      },
      "outputs": [],
      "source": [
        "# Get Ngrok authentication token from colab secrets environment\n",
        "from google.colab import userdata\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "DOMAIN = userdata.get('DOMAIN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsdchffjnHep",
        "outputId": "e0a472fc-e512-4509-e073-ed57740c3979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.5)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.10)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n",
            ">>> starting ngrok config add-authtoken 2mEhdLXAfKTrmSztMmBoQAsZ4ru_7FiF1KKjGqNnJYApV8iGj\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Install:\n",
        "#  1. aiohttp for concurrent subprocess execution in Jupyter Notebooks\n",
        "#  2. pyngrok for Ngrok wrapper\n",
        "!pip install aiohttp pyngrok\n",
        "\n",
        "import asyncio\n",
        "import os\n",
        "\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library becomes preferred\n",
        "# over the built-in library. This is particularly important for\n",
        "# Google Colab which installs older drivers\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "\n",
        "# Define run - a helper function to run subcommands asynchronously.\n",
        "# The function takes in 2 arguments:\n",
        "#  1. command\n",
        "#  2. environment variable\n",
        "async def run(cmd):\n",
        "  print('>>> starting', *cmd)\n",
        "  p = await asyncio.subprocess.create_subprocess_exec(\n",
        "      *cmd,\n",
        "      stdout=asyncio.subprocess.PIPE,\n",
        "      stderr=asyncio.subprocess.PIPE\n",
        "  )\n",
        "\n",
        "\n",
        "# This function is designed to handle large amounts of text data efficiently.\n",
        "# It asynchronously iterate over lines and print them, stripping and decoding as needed.\n",
        "  async def pipe(lines):\n",
        "    async for line in lines:\n",
        "      print(line.strip().decode('utf-8'))\n",
        "\n",
        "\n",
        "# Gather the standard output (stdout) and standard error output (stderr) streams of a subprocess and pipe them through\n",
        "# the `pipe()` function to print each line after stripping whitespace and decoding UTF-8.\n",
        "# This allows us to capture and process both the standard output and error messages from the subprocess concurrently.\n",
        "  await asyncio.gather(\n",
        "      pipe(p.stdout),\n",
        "      pipe(p.stderr),\n",
        "  )\n",
        "\n",
        "\n",
        "# Authenticate with Ngrok\n",
        "await asyncio.gather(\n",
        "  run(['ngrok', 'config', 'add-authtoken', NGROK_AUTH_TOKEN])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6JGeZqlnVn7",
        "outputId": "5aadf875-1be0-4299-8fa2-cba7c555898c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> starting ollama serve\n",
            ">>> starting ngrok http --log stderr 11434 --host-header localhost:11434 --domain able-mayfly-driven.ngrok-free.app\n",
            "Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\n",
            "Your new public key is:\n",
            "\n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMR8tdiz0XEdbTxdisbYY9pX1uEmpSNNlB6hIGL8y9RG\n",
            "\n",
            "2024/09/19 21:32:29 routes.go:1153: INFO server config env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR: ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]\"\n",
            "time=2024-09-19T21:32:29.805Z level=INFO source=images.go:753 msg=\"total blobs: 0\"\n",
            "time=2024-09-19T21:32:29.805Z level=INFO source=images.go:760 msg=\"total unused blobs removed: 0\"\n",
            "time=2024-09-19T21:32:29.809Z level=INFO source=routes.go:1200 msg=\"Listening on 127.0.0.1:11434 (version 0.3.11)\"\n",
            "time=2024-09-19T21:32:29.812Z level=INFO source=common.go:135 msg=\"extracting embedded files\" dir=/tmp/ollama3690793497/runners\n",
            "t=2024-09-19T21:32:30+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "t=2024-09-19T21:32:30+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "t=2024-09-19T21:32:30+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "t=2024-09-19T21:32:30+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2024-09-19T21:32:30+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2024-09-19T21:32:30+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2024-09-19T21:32:31+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:11434 url=https://able-mayfly-driven.ngrok-free.app\n",
            "t=2024-09-19T21:33:09+0000 lvl=info msg=\"join connections\" obj=join id=2e348b985c2d l=127.0.0.1:11434 r=160.202.37.200:49614\n",
            "time=2024-09-19T21:33:13.080Z level=INFO source=common.go:49 msg=\"Dynamic LLM libraries\" runners=\"[cpu cpu_avx cpu_avx2 cuda_v11 cuda_v12 rocm_v60102]\"\n",
            "time=2024-09-19T21:33:13.081Z level=INFO source=gpu.go:199 msg=\"looking for compatible GPUs\"\n",
            "time=2024-09-19T21:33:13.349Z level=INFO source=types.go:107 msg=\"inference compute\" id=GPU-ccd7e713-5603-b5ab-34f0-3c2f4efe8f7f library=cuda variant=v12 compute=7.5 driver=12.2 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n",
            "[GIN] 2024/09/19 - 21:33:13 | 200 |      66.028µs |  160.202.37.200 | HEAD     \"/\"\n",
            "[GIN] 2024/09/19 - 21:33:13 | 200 |     327.003µs |  160.202.37.200 | GET      \"/api/tags\"\n",
            "t=2024-09-19T21:33:20+0000 lvl=info msg=\"join connections\" obj=join id=c849fc30009d l=127.0.0.1:11434 r=160.202.37.200:49615\n",
            "[GIN] 2024/09/19 - 21:33:20 | 200 |      32.525µs |  160.202.37.200 | HEAD     \"/\"\n",
            "[GIN] 2024/09/19 - 21:33:20 | 404 |     247.088µs |  160.202.37.200 | POST     \"/api/show\"\n",
            "time=2024-09-19T21:33:23.462Z level=INFO source=download.go:175 msg=\"downloading 8934d96d3f08 in 16 239 MB part(s)\"\n",
            "time=2024-09-19T21:33:46.702Z level=INFO source=download.go:175 msg=\"downloading 8c17c2ebb0ea in 1 7.0 KB part(s)\"\n",
            "time=2024-09-19T21:33:49.000Z level=INFO source=download.go:175 msg=\"downloading 7c23fb36d801 in 1 4.8 KB part(s)\"\n",
            "time=2024-09-19T21:33:51.419Z level=INFO source=download.go:175 msg=\"downloading 2e0493f67d0c in 1 59 B part(s)\"\n",
            "time=2024-09-19T21:33:53.779Z level=INFO source=download.go:175 msg=\"downloading fa304d675061 in 1 91 B part(s)\"\n",
            "time=2024-09-19T21:33:57.028Z level=INFO source=download.go:175 msg=\"downloading 42ba7f8a01dd in 1 557 B part(s)\"\n",
            "[GIN] 2024/09/19 - 21:34:15 | 200 | 53.872592044s |  160.202.37.200 | POST     \"/api/pull\"\n",
            "[GIN] 2024/09/19 - 21:34:15 | 200 |   19.356667ms |  160.202.37.200 | POST     \"/api/show\"\n",
            "time=2024-09-19T21:34:16.758Z level=INFO source=sched.go:714 msg=\"new model will fit in available VRAM in single GPU, loading\" model=/root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 gpu=GPU-ccd7e713-5603-b5ab-34f0-3c2f4efe8f7f parallel=4 available=15727656960 required=\"8.7 GiB\"\n",
            "time=2024-09-19T21:34:16.758Z level=INFO source=server.go:103 msg=\"system memory\" total=\"12.7 GiB\" free=\"11.4 GiB\" free_swap=\"0 B\"\n",
            "time=2024-09-19T21:34:16.759Z level=INFO source=memory.go:326 msg=\"offload to cuda\" layers.requested=-1 layers.model=33 layers.offload=33 layers.split=\"\" memory.available=\"[14.6 GiB]\" memory.gpu_overhead=\"0 B\" memory.required.full=\"8.7 GiB\" memory.required.partial=\"8.7 GiB\" memory.required.kv=\"4.0 GiB\" memory.required.allocations=\"[8.7 GiB]\" memory.weights.total=\"7.4 GiB\" memory.weights.repeating=\"7.3 GiB\" memory.weights.nonrepeating=\"102.6 MiB\" memory.graph.full=\"560.0 MiB\" memory.graph.partial=\"681.0 MiB\"\n",
            "time=2024-09-19T21:34:16.761Z level=INFO source=server.go:388 msg=\"starting llama server\" cmd=\"/tmp/ollama3690793497/runners/cuda_v12/ollama_llama_server --model /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 --ctx-size 8192 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 4 --port 35845\"\n",
            "time=2024-09-19T21:34:16.764Z level=INFO source=sched.go:449 msg=\"loaded runners\" count=1\n",
            "time=2024-09-19T21:34:16.764Z level=INFO source=server.go:587 msg=\"waiting for llama runner to start responding\"\n",
            "time=2024-09-19T21:34:16.765Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server error\"\n",
            "INFO [main] build info | build=10 commit=\"9225b05\" tid=\"135584839458816\" timestamp=1726781657\n",
            "INFO [main] system info | n_threads=1 n_threads_batch=1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"135584839458816\" timestamp=1726781657 total_threads=2\n",
            "INFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"6\" port=\"35845\" tid=\"135584839458816\" timestamp=1726781657\n",
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,61249]   = [\"▁ t\", \"e r\", \"i n\", \"▁ a\", \"e n...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "time=2024-09-19T21:34:17.517Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server loading model\"\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW)\n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  3577.56 MiB\n",
            "llama_new_context_with_model: n_ctx      = 8192\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  4096.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.55 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "INFO [main] model loaded | tid=\"135584839458816\" timestamp=1726781663\n",
            "time=2024-09-19T21:34:23.546Z level=INFO source=server.go:626 msg=\"llama runner started in 6.78 seconds\"\n",
            "[GIN] 2024/09/19 - 21:34:23 | 200 |   6.98114206s |  160.202.37.200 | POST     \"/api/chat\"\n",
            "t=2024-09-19T21:39:26+0000 lvl=info msg=\"join connections\" obj=join id=28e82be781a3 l=127.0.0.1:11434 r=160.202.37.200:49943\n",
            "time=2024-09-19T21:39:26.367Z level=INFO source=sched.go:714 msg=\"new model will fit in available VRAM in single GPU, loading\" model=/root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 gpu=GPU-ccd7e713-5603-b5ab-34f0-3c2f4efe8f7f parallel=4 available=15727656960 required=\"8.7 GiB\"\n",
            "time=2024-09-19T21:39:26.367Z level=INFO source=server.go:103 msg=\"system memory\" total=\"12.7 GiB\" free=\"11.4 GiB\" free_swap=\"0 B\"\n",
            "time=2024-09-19T21:39:26.368Z level=INFO source=memory.go:326 msg=\"offload to cuda\" layers.requested=-1 layers.model=33 layers.offload=33 layers.split=\"\" memory.available=\"[14.6 GiB]\" memory.gpu_overhead=\"0 B\" memory.required.full=\"8.7 GiB\" memory.required.partial=\"8.7 GiB\" memory.required.kv=\"4.0 GiB\" memory.required.allocations=\"[8.7 GiB]\" memory.weights.total=\"7.4 GiB\" memory.weights.repeating=\"7.3 GiB\" memory.weights.nonrepeating=\"102.6 MiB\" memory.graph.full=\"560.0 MiB\" memory.graph.partial=\"681.0 MiB\"\n",
            "time=2024-09-19T21:39:26.371Z level=INFO source=server.go:388 msg=\"starting llama server\" cmd=\"/tmp/ollama3690793497/runners/cuda_v12/ollama_llama_server --model /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 --ctx-size 8192 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 4 --port 43397\"\n",
            "time=2024-09-19T21:39:26.372Z level=INFO source=sched.go:449 msg=\"loaded runners\" count=1\n",
            "time=2024-09-19T21:39:26.372Z level=INFO source=server.go:587 msg=\"waiting for llama runner to start responding\"\n",
            "time=2024-09-19T21:39:26.372Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server error\"\n",
            "INFO [main] build info | build=10 commit=\"9225b05\" tid=\"138840612261888\" timestamp=1726781966\n",
            "INFO [main] system info | n_threads=1 n_threads_batch=1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"138840612261888\" timestamp=1726781966 total_threads=2\n",
            "INFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"6\" port=\"43397\" tid=\"138840612261888\" timestamp=1726781966\n",
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,61249]   = [\"▁ t\", \"e r\", \"i n\", \"▁ a\", \"e n...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW)\n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
            "time=2024-09-19T21:39:26.806Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server loading model\"\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  3577.56 MiB\n",
            "llama_new_context_with_model: n_ctx      = 8192\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  4096.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.55 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "INFO [main] model loaded | tid=\"138840612261888\" timestamp=1726781968\n",
            "time=2024-09-19T21:39:28.062Z level=INFO source=server.go:626 msg=\"llama runner started in 1.69 seconds\"\n",
            "[GIN] 2024/09/19 - 21:39:56 | 200 | 30.638391467s |  160.202.37.200 | POST     \"/api/chat\"\n",
            "t=2024-09-19T21:42:51+0000 lvl=info msg=\"join connections\" obj=join id=43f1b4fdf96f l=127.0.0.1:11434 r=160.202.37.200:50088\n",
            "[GIN] 2024/09/19 - 21:43:07 | 200 | 16.557939328s |  160.202.37.200 | POST     \"/api/chat\"\n",
            "t=2024-09-19T21:57:12+0000 lvl=info msg=\"join connections\" obj=join id=af7e9499a19c l=127.0.0.1:11434 r=160.202.37.200:50791\n",
            "time=2024-09-19T21:57:12.414Z level=INFO source=sched.go:714 msg=\"new model will fit in available VRAM in single GPU, loading\" model=/root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 gpu=GPU-ccd7e713-5603-b5ab-34f0-3c2f4efe8f7f parallel=4 available=15727656960 required=\"8.7 GiB\"\n",
            "time=2024-09-19T21:57:12.414Z level=INFO source=server.go:103 msg=\"system memory\" total=\"12.7 GiB\" free=\"11.4 GiB\" free_swap=\"0 B\"\n",
            "time=2024-09-19T21:57:12.415Z level=INFO source=memory.go:326 msg=\"offload to cuda\" layers.requested=-1 layers.model=33 layers.offload=33 layers.split=\"\" memory.available=\"[14.6 GiB]\" memory.gpu_overhead=\"0 B\" memory.required.full=\"8.7 GiB\" memory.required.partial=\"8.7 GiB\" memory.required.kv=\"4.0 GiB\" memory.required.allocations=\"[8.7 GiB]\" memory.weights.total=\"7.4 GiB\" memory.weights.repeating=\"7.3 GiB\" memory.weights.nonrepeating=\"102.6 MiB\" memory.graph.full=\"560.0 MiB\" memory.graph.partial=\"681.0 MiB\"\n",
            "time=2024-09-19T21:57:12.418Z level=INFO source=server.go:388 msg=\"starting llama server\" cmd=\"/tmp/ollama3690793497/runners/cuda_v12/ollama_llama_server --model /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 --ctx-size 8192 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 4 --port 39575\"\n",
            "time=2024-09-19T21:57:12.420Z level=INFO source=sched.go:449 msg=\"loaded runners\" count=1\n",
            "time=2024-09-19T21:57:12.420Z level=INFO source=server.go:587 msg=\"waiting for llama runner to start responding\"\n",
            "time=2024-09-19T21:57:12.421Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server error\"\n",
            "INFO [main] build info | build=10 commit=\"9225b05\" tid=\"137498329100288\" timestamp=1726783032\n",
            "INFO [main] system info | n_threads=1 n_threads_batch=1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"137498329100288\" timestamp=1726783032 total_threads=2\n",
            "INFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"6\" port=\"39575\" tid=\"137498329100288\" timestamp=1726783032\n",
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,61249]   = [\"▁ t\", \"e r\", \"i n\", \"▁ a\", \"e n...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW)\n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
            "time=2024-09-19T21:57:12.869Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server loading model\"\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  3577.56 MiB\n",
            "llama_new_context_with_model: n_ctx      = 8192\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  4096.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.55 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "INFO [main] model loaded | tid=\"137498329100288\" timestamp=1726783034\n",
            "time=2024-09-19T21:57:14.125Z level=INFO source=server.go:626 msg=\"llama runner started in 1.70 seconds\"\n",
            "[GIN] 2024/09/19 - 21:57:14 | 200 |  2.261128749s |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:16+0000 lvl=info msg=\"join connections\" obj=join id=5232f35cedb9 l=127.0.0.1:11434 r=160.202.37.200:50793\n",
            "[GIN] 2024/09/19 - 21:57:16 | 200 |  243.127762ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:17+0000 lvl=info msg=\"join connections\" obj=join id=e70f02223032 l=127.0.0.1:11434 r=160.202.37.200:50794\n",
            "[GIN] 2024/09/19 - 21:57:18 | 200 |  225.735408ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:19+0000 lvl=info msg=\"join connections\" obj=join id=10ebe1f83797 l=127.0.0.1:11434 r=160.202.37.200:50795\n",
            "[GIN] 2024/09/19 - 21:57:19 | 200 |  183.481284ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:20+0000 lvl=info msg=\"join connections\" obj=join id=4c6f513506a5 l=127.0.0.1:11434 r=160.202.37.200:50796\n",
            "[GIN] 2024/09/19 - 21:57:21 | 200 |  261.070425ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:22+0000 lvl=info msg=\"join connections\" obj=join id=566cc2dd93cc l=127.0.0.1:11434 r=160.202.37.200:50797\n",
            "[GIN] 2024/09/19 - 21:57:22 | 200 |  226.653962ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:23+0000 lvl=info msg=\"join connections\" obj=join id=7b91f718ea1d l=127.0.0.1:11434 r=160.202.37.200:50799\n",
            "[GIN] 2024/09/19 - 21:57:23 | 200 |  225.516603ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:25+0000 lvl=info msg=\"join connections\" obj=join id=8ec63a1dce01 l=127.0.0.1:11434 r=160.202.37.200:50800\n",
            "[GIN] 2024/09/19 - 21:57:25 | 200 |  183.281253ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:27+0000 lvl=info msg=\"join connections\" obj=join id=4dd14b6c719a l=127.0.0.1:11434 r=160.202.37.200:50801\n",
            "[GIN] 2024/09/19 - 21:57:27 | 200 |  215.894181ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:28+0000 lvl=info msg=\"join connections\" obj=join id=226e7d2ecdf2 l=127.0.0.1:11434 r=160.202.37.200:50802\n",
            "[GIN] 2024/09/19 - 21:57:28 | 200 |  267.626943ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:30+0000 lvl=info msg=\"join connections\" obj=join id=ae93d594c086 l=127.0.0.1:11434 r=160.202.37.200:50803\n",
            "[GIN] 2024/09/19 - 21:57:30 | 200 |  251.988812ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:31+0000 lvl=info msg=\"join connections\" obj=join id=33edfab06084 l=127.0.0.1:11434 r=160.202.37.200:50805\n",
            "[GIN] 2024/09/19 - 21:57:32 | 200 |  226.391987ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:33+0000 lvl=info msg=\"join connections\" obj=join id=0dad194fe64a l=127.0.0.1:11434 r=160.202.37.200:50807\n",
            "[GIN] 2024/09/19 - 21:57:33 | 200 |  186.447328ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:34+0000 lvl=info msg=\"join connections\" obj=join id=f5f121969a46 l=127.0.0.1:11434 r=160.202.37.200:50809\n",
            "[GIN] 2024/09/19 - 21:57:35 | 200 |  286.370534ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:36+0000 lvl=info msg=\"join connections\" obj=join id=7a28178d7a50 l=127.0.0.1:11434 r=160.202.37.200:50810\n",
            "[GIN] 2024/09/19 - 21:57:36 | 200 |  281.042856ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:38+0000 lvl=info msg=\"join connections\" obj=join id=89b59f813397 l=127.0.0.1:11434 r=160.202.37.200:50812\n",
            "[GIN] 2024/09/19 - 21:57:38 | 200 |  248.232648ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:40+0000 lvl=info msg=\"join connections\" obj=join id=342d7f1dd910 l=127.0.0.1:11434 r=160.202.37.200:50813\n",
            "[GIN] 2024/09/19 - 21:57:40 | 200 |  115.816899ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:41+0000 lvl=info msg=\"join connections\" obj=join id=fe03fd1e3b4e l=127.0.0.1:11434 r=160.202.37.200:50814\n",
            "[GIN] 2024/09/19 - 21:57:42 | 200 |  413.619067ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:43+0000 lvl=info msg=\"join connections\" obj=join id=6ae894610117 l=127.0.0.1:11434 r=160.202.37.200:50815\n",
            "[GIN] 2024/09/19 - 21:57:43 | 200 |   278.68244ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:44+0000 lvl=info msg=\"join connections\" obj=join id=c5e55018355a l=127.0.0.1:11434 r=160.202.37.200:50817\n",
            "[GIN] 2024/09/19 - 21:57:45 | 200 |  286.192618ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:46+0000 lvl=info msg=\"join connections\" obj=join id=ae71540f9409 l=127.0.0.1:11434 r=160.202.37.200:50818\n",
            "[GIN] 2024/09/19 - 21:57:46 | 200 |   155.46154ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:48+0000 lvl=info msg=\"join connections\" obj=join id=1bc4df6e753b l=127.0.0.1:11434 r=160.202.37.200:50819\n",
            "[GIN] 2024/09/19 - 21:57:48 | 200 |   247.99685ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:49+0000 lvl=info msg=\"join connections\" obj=join id=60fa7a767d03 l=127.0.0.1:11434 r=160.202.37.200:50820\n",
            "[GIN] 2024/09/19 - 21:57:49 | 200 |  243.979572ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:51+0000 lvl=info msg=\"join connections\" obj=join id=966f3a5cb3a2 l=127.0.0.1:11434 r=160.202.37.200:50821\n",
            "[GIN] 2024/09/19 - 21:57:51 | 200 |  295.132011ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:52+0000 lvl=info msg=\"join connections\" obj=join id=1a2e6ac1dfcc l=127.0.0.1:11434 r=160.202.37.200:50822\n",
            "[GIN] 2024/09/19 - 21:57:52 | 200 |   190.38015ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:54+0000 lvl=info msg=\"join connections\" obj=join id=cbc7fa4f0fa3 l=127.0.0.1:11434 r=160.202.37.200:50824\n",
            "[GIN] 2024/09/19 - 21:57:54 | 200 |  508.527437ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:56+0000 lvl=info msg=\"join connections\" obj=join id=0c6463ac1d5e l=127.0.0.1:11434 r=160.202.37.200:50825\n",
            "[GIN] 2024/09/19 - 21:57:56 | 200 |  329.201535ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:58+0000 lvl=info msg=\"join connections\" obj=join id=ab2b0af3527a l=127.0.0.1:11434 r=160.202.37.200:50826\n",
            "[GIN] 2024/09/19 - 21:57:58 | 200 |  252.679928ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:57:59+0000 lvl=info msg=\"join connections\" obj=join id=d1beac8a4d53 l=127.0.0.1:11434 r=160.202.37.200:50827\n",
            "[GIN] 2024/09/19 - 21:57:59 | 200 |   93.490074ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:58:01+0000 lvl=info msg=\"join connections\" obj=join id=43fff52aa6ba l=127.0.0.1:11434 r=160.202.37.200:50828\n",
            "[GIN] 2024/09/19 - 21:58:02 | 200 |  657.238599ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:01+0000 lvl=info msg=\"join connections\" obj=join id=a51b43f8ec4f l=127.0.0.1:11434 r=160.202.37.200:50841\n",
            "[GIN] 2024/09/19 - 21:59:02 | 200 |  429.310991ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:03+0000 lvl=info msg=\"join connections\" obj=join id=611aee218107 l=127.0.0.1:11434 r=160.202.37.200:50842\n",
            "[GIN] 2024/09/19 - 21:59:03 | 200 |  213.679858ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:05+0000 lvl=info msg=\"join connections\" obj=join id=0b841de8183f l=127.0.0.1:11434 r=160.202.37.200:50843\n",
            "[GIN] 2024/09/19 - 21:59:05 | 200 |  230.565749ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:06+0000 lvl=info msg=\"join connections\" obj=join id=f0da27d7d5e8 l=127.0.0.1:11434 r=160.202.37.200:50844\n",
            "[GIN] 2024/09/19 - 21:59:06 | 200 |  188.526506ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:08+0000 lvl=info msg=\"join connections\" obj=join id=4826efc96aef l=127.0.0.1:11434 r=160.202.37.200:50845\n",
            "[GIN] 2024/09/19 - 21:59:08 | 200 |  274.629331ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:09+0000 lvl=info msg=\"join connections\" obj=join id=4a522e9258c9 l=127.0.0.1:11434 r=160.202.37.200:50846\n",
            "[GIN] 2024/09/19 - 21:59:09 | 200 |  230.142959ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:11+0000 lvl=info msg=\"join connections\" obj=join id=7cdadbee051c l=127.0.0.1:11434 r=160.202.37.200:50847\n",
            "[GIN] 2024/09/19 - 21:59:11 | 200 |   234.16987ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:12+0000 lvl=info msg=\"join connections\" obj=join id=bf8cf298cf76 l=127.0.0.1:11434 r=160.202.37.200:50848\n",
            "[GIN] 2024/09/19 - 21:59:12 | 200 |  189.024057ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:14+0000 lvl=info msg=\"join connections\" obj=join id=8b1a9a3ff6bd l=127.0.0.1:11434 r=160.202.37.200:50849\n",
            "[GIN] 2024/09/19 - 21:59:14 | 200 |  216.010003ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:15+0000 lvl=info msg=\"join connections\" obj=join id=0c14a5208476 l=127.0.0.1:11434 r=160.202.37.200:50851\n",
            "[GIN] 2024/09/19 - 21:59:16 | 200 |  274.537916ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:17+0000 lvl=info msg=\"join connections\" obj=join id=0b2d963f1b04 l=127.0.0.1:11434 r=160.202.37.200:50852\n",
            "[GIN] 2024/09/19 - 21:59:17 | 200 |  257.498794ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:18+0000 lvl=info msg=\"join connections\" obj=join id=3ba813454433 l=127.0.0.1:11434 r=160.202.37.200:50853\n",
            "[GIN] 2024/09/19 - 21:59:19 | 200 |  231.671968ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:20+0000 lvl=info msg=\"join connections\" obj=join id=fece3ee688ae l=127.0.0.1:11434 r=160.202.37.200:50854\n",
            "[GIN] 2024/09/19 - 21:59:20 | 200 |  190.299262ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:21+0000 lvl=info msg=\"join connections\" obj=join id=a995f44e92cc l=127.0.0.1:11434 r=160.202.37.200:50855\n",
            "[GIN] 2024/09/19 - 21:59:22 | 200 |  311.366765ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:23+0000 lvl=info msg=\"join connections\" obj=join id=d45952fe1958 l=127.0.0.1:11434 r=160.202.37.200:50856\n",
            "[GIN] 2024/09/19 - 21:59:23 | 200 |  290.593979ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:25+0000 lvl=info msg=\"join connections\" obj=join id=8e857f204c3e l=127.0.0.1:11434 r=160.202.37.200:50857\n",
            "[GIN] 2024/09/19 - 21:59:25 | 200 |  255.685087ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:26+0000 lvl=info msg=\"join connections\" obj=join id=c31fe24cd5f3 l=127.0.0.1:11434 r=160.202.37.200:50859\n",
            "[GIN] 2024/09/19 - 21:59:26 | 200 |  121.908616ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:28+0000 lvl=info msg=\"join connections\" obj=join id=f42d58e19661 l=127.0.0.1:11434 r=160.202.37.200:50860\n",
            "[GIN] 2024/09/19 - 21:59:28 | 200 |  372.288192ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:29+0000 lvl=info msg=\"join connections\" obj=join id=694ea38d0632 l=127.0.0.1:11434 r=160.202.37.200:50861\n",
            "[GIN] 2024/09/19 - 21:59:29 | 200 |  285.478259ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:30+0000 lvl=info msg=\"join connections\" obj=join id=5b8077ae710b l=127.0.0.1:11434 r=160.202.37.200:50862\n",
            "[GIN] 2024/09/19 - 21:59:31 | 200 |  386.319894ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:32+0000 lvl=info msg=\"join connections\" obj=join id=10b49deb0294 l=127.0.0.1:11434 r=160.202.37.200:50863\n",
            "[GIN] 2024/09/19 - 21:59:32 | 200 |  154.521987ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:34+0000 lvl=info msg=\"join connections\" obj=join id=a823f2f936b9 l=127.0.0.1:11434 r=160.202.37.200:50864\n",
            "[GIN] 2024/09/19 - 21:59:34 | 200 |  251.737374ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:35+0000 lvl=info msg=\"join connections\" obj=join id=4639b3ba8e7f l=127.0.0.1:11434 r=160.202.37.200:50865\n",
            "[GIN] 2024/09/19 - 21:59:36 | 200 |  259.944174ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:37+0000 lvl=info msg=\"join connections\" obj=join id=2a203d8f6c07 l=127.0.0.1:11434 r=160.202.37.200:50866\n",
            "[GIN] 2024/09/19 - 21:59:37 | 200 |  303.491809ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:38+0000 lvl=info msg=\"join connections\" obj=join id=8cc36010d18d l=127.0.0.1:11434 r=160.202.37.200:50867\n",
            "[GIN] 2024/09/19 - 21:59:39 | 200 |  190.230215ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:40+0000 lvl=info msg=\"join connections\" obj=join id=9b2e92d80027 l=127.0.0.1:11434 r=160.202.37.200:50868\n",
            "[GIN] 2024/09/19 - 21:59:41 | 200 |  527.095291ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:42+0000 lvl=info msg=\"join connections\" obj=join id=7da68376c39b l=127.0.0.1:11434 r=160.202.37.200:50869\n",
            "[GIN] 2024/09/19 - 21:59:42 | 200 |  301.593141ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:43+0000 lvl=info msg=\"join connections\" obj=join id=5cd3703262f1 l=127.0.0.1:11434 r=160.202.37.200:50870\n",
            "[GIN] 2024/09/19 - 21:59:44 | 200 |  256.172659ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:45+0000 lvl=info msg=\"join connections\" obj=join id=43b3d84dd065 l=127.0.0.1:11434 r=160.202.37.200:50871\n",
            "[GIN] 2024/09/19 - 21:59:45 | 200 |   93.492547ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:47+0000 lvl=info msg=\"join connections\" obj=join id=156683d59a03 l=127.0.0.1:11434 r=160.202.37.200:50873\n",
            "[GIN] 2024/09/19 - 21:59:47 | 200 |  594.130239ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:55+0000 lvl=info msg=\"join connections\" obj=join id=f16a85a8174e l=127.0.0.1:11434 r=160.202.37.200:50875\n",
            "[GIN] 2024/09/19 - 21:59:55 | 200 |  428.251417ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:57+0000 lvl=info msg=\"join connections\" obj=join id=761267873920 l=127.0.0.1:11434 r=160.202.37.200:50876\n",
            "[GIN] 2024/09/19 - 21:59:57 | 200 |  255.031854ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T21:59:59+0000 lvl=info msg=\"join connections\" obj=join id=b32c4fed3b8b l=127.0.0.1:11434 r=160.202.37.200:50877\n",
            "[GIN] 2024/09/19 - 21:59:59 | 200 |  224.840183ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:00+0000 lvl=info msg=\"join connections\" obj=join id=5968d9add16e l=127.0.0.1:11434 r=160.202.37.200:50878\n",
            "[GIN] 2024/09/19 - 22:00:00 | 200 |  193.952068ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:02+0000 lvl=info msg=\"join connections\" obj=join id=6dd160c4491f l=127.0.0.1:11434 r=160.202.37.200:50879\n",
            "[GIN] 2024/09/19 - 22:00:02 | 200 |  274.964406ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:03+0000 lvl=info msg=\"join connections\" obj=join id=f04857003d98 l=127.0.0.1:11434 r=160.202.37.200:50880\n",
            "[GIN] 2024/09/19 - 22:00:04 | 200 |  232.550278ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:05+0000 lvl=info msg=\"join connections\" obj=join id=960e239ed026 l=127.0.0.1:11434 r=160.202.37.200:50881\n",
            "[GIN] 2024/09/19 - 22:00:05 | 200 |  243.642759ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:06+0000 lvl=info msg=\"join connections\" obj=join id=5f1afd623ed3 l=127.0.0.1:11434 r=160.202.37.200:50882\n",
            "[GIN] 2024/09/19 - 22:00:07 | 200 |  189.563939ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:08+0000 lvl=info msg=\"join connections\" obj=join id=53ff1dbe78b6 l=127.0.0.1:11434 r=160.202.37.200:50883\n",
            "[GIN] 2024/09/19 - 22:00:08 | 200 |  219.696962ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:10+0000 lvl=info msg=\"join connections\" obj=join id=49e7e980f351 l=127.0.0.1:11434 r=160.202.37.200:50884\n",
            "[GIN] 2024/09/19 - 22:00:10 | 200 |  284.747178ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:11+0000 lvl=info msg=\"join connections\" obj=join id=e5119e33481c l=127.0.0.1:11434 r=160.202.37.200:50885\n",
            "[GIN] 2024/09/19 - 22:00:11 | 200 |  263.143382ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:13+0000 lvl=info msg=\"join connections\" obj=join id=6a331899618c l=127.0.0.1:11434 r=160.202.37.200:50887\n",
            "[GIN] 2024/09/19 - 22:00:13 | 200 |  240.679722ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:14+0000 lvl=info msg=\"join connections\" obj=join id=ed0be0cf9d6e l=127.0.0.1:11434 r=160.202.37.200:50888\n",
            "[GIN] 2024/09/19 - 22:00:15 | 200 |  195.645515ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:16+0000 lvl=info msg=\"join connections\" obj=join id=d68e5eafe685 l=127.0.0.1:11434 r=160.202.37.200:50890\n",
            "[GIN] 2024/09/19 - 22:00:16 | 200 |  313.771299ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:17+0000 lvl=info msg=\"join connections\" obj=join id=7de09a301a84 l=127.0.0.1:11434 r=160.202.37.200:50891\n",
            "[GIN] 2024/09/19 - 22:00:18 | 200 |   294.99253ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:19+0000 lvl=info msg=\"join connections\" obj=join id=df6a5005cd99 l=127.0.0.1:11434 r=160.202.37.200:50892\n",
            "[GIN] 2024/09/19 - 22:00:19 | 200 |  257.396053ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:21+0000 lvl=info msg=\"join connections\" obj=join id=5b60c906f9c1 l=127.0.0.1:11434 r=160.202.37.200:50893\n",
            "[GIN] 2024/09/19 - 22:00:21 | 200 |   127.23589ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:22+0000 lvl=info msg=\"join connections\" obj=join id=66444a52768d l=127.0.0.1:11434 r=160.202.37.200:50894\n",
            "[GIN] 2024/09/19 - 22:00:23 | 200 |  395.981211ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:24+0000 lvl=info msg=\"join connections\" obj=join id=469855a13b85 l=127.0.0.1:11434 r=160.202.37.200:50896\n",
            "[GIN] 2024/09/19 - 22:00:24 | 200 |   296.93694ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:26+0000 lvl=info msg=\"join connections\" obj=join id=6a30bd0f8ec5 l=127.0.0.1:11434 r=160.202.37.200:50897\n",
            "[GIN] 2024/09/19 - 22:00:26 | 200 |  303.167466ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:28+0000 lvl=info msg=\"join connections\" obj=join id=db9ef6f77e30 l=127.0.0.1:11434 r=160.202.37.200:50898\n",
            "[GIN] 2024/09/19 - 22:00:28 | 200 |  163.594368ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:29+0000 lvl=info msg=\"join connections\" obj=join id=ed3d3e9f7fe1 l=127.0.0.1:11434 r=160.202.37.200:50902\n",
            "[GIN] 2024/09/19 - 22:00:29 | 200 |  251.852965ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:31+0000 lvl=info msg=\"join connections\" obj=join id=7a520c6452e5 l=127.0.0.1:11434 r=160.202.37.200:50904\n",
            "[GIN] 2024/09/19 - 22:00:31 | 200 |  263.152598ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:32+0000 lvl=info msg=\"join connections\" obj=join id=887c8bc4a379 l=127.0.0.1:11434 r=160.202.37.200:50905\n",
            "[GIN] 2024/09/19 - 22:00:33 | 200 |  322.174067ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:34+0000 lvl=info msg=\"join connections\" obj=join id=81caafe77610 l=127.0.0.1:11434 r=160.202.37.200:50906\n",
            "[GIN] 2024/09/19 - 22:00:34 | 200 |  195.430608ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:36+0000 lvl=info msg=\"join connections\" obj=join id=1d5aeabdf0e0 l=127.0.0.1:11434 r=160.202.37.200:50907\n",
            "[GIN] 2024/09/19 - 22:00:36 | 200 |  546.844337ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:38+0000 lvl=info msg=\"join connections\" obj=join id=84c3d42adf8b l=127.0.0.1:11434 r=160.202.37.200:50908\n",
            "[GIN] 2024/09/19 - 22:00:38 | 200 |  356.123498ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:39+0000 lvl=info msg=\"join connections\" obj=join id=8041d5106f67 l=127.0.0.1:11434 r=160.202.37.200:50909\n",
            "[GIN] 2024/09/19 - 22:00:39 | 200 |   264.14901ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:41+0000 lvl=info msg=\"join connections\" obj=join id=a0fcaa665d12 l=127.0.0.1:11434 r=160.202.37.200:50910\n",
            "[GIN] 2024/09/19 - 22:00:41 | 200 |   96.758125ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:42+0000 lvl=info msg=\"join connections\" obj=join id=ae687a2e9ea9 l=127.0.0.1:11434 r=160.202.37.200:50911\n",
            "[GIN] 2024/09/19 - 22:00:43 | 200 |  704.205916ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:44+0000 lvl=info msg=\"join connections\" obj=join id=0b8ce3a27084 l=127.0.0.1:11434 r=160.202.37.200:50912\n",
            "[GIN] 2024/09/19 - 22:00:45 | 200 |  271.183526ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:46+0000 lvl=info msg=\"join connections\" obj=join id=dbd12ce03e05 l=127.0.0.1:11434 r=160.202.37.200:50913\n",
            "[GIN] 2024/09/19 - 22:00:46 | 200 |  265.843339ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:48+0000 lvl=info msg=\"join connections\" obj=join id=9879d5c0a844 l=127.0.0.1:11434 r=160.202.37.200:50915\n",
            "[GIN] 2024/09/19 - 22:00:48 | 200 |  110.587538ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:50+0000 lvl=info msg=\"join connections\" obj=join id=aacbf5327361 l=127.0.0.1:11434 r=160.202.37.200:50916\n",
            "[GIN] 2024/09/19 - 22:00:50 | 200 |   486.01422ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:52+0000 lvl=info msg=\"join connections\" obj=join id=82c3f0034f1a l=127.0.0.1:11434 r=160.202.37.200:50918\n",
            "[GIN] 2024/09/19 - 22:00:52 | 200 |  305.868643ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:53+0000 lvl=info msg=\"join connections\" obj=join id=1ee805ef7feb l=127.0.0.1:11434 r=160.202.37.200:50919\n",
            "[GIN] 2024/09/19 - 22:00:53 | 200 |   361.56917ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:55+0000 lvl=info msg=\"join connections\" obj=join id=c18c4bd6b3e4 l=127.0.0.1:11434 r=160.202.37.200:50920\n",
            "[GIN] 2024/09/19 - 22:00:55 | 200 |  121.029587ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:56+0000 lvl=info msg=\"join connections\" obj=join id=3f72e32b8eb2 l=127.0.0.1:11434 r=160.202.37.200:50921\n",
            "[GIN] 2024/09/19 - 22:00:57 | 200 |  455.408096ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:58+0000 lvl=info msg=\"join connections\" obj=join id=0b3916e31673 l=127.0.0.1:11434 r=160.202.37.200:50922\n",
            "[GIN] 2024/09/19 - 22:00:58 | 200 |  359.703737ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:00:59+0000 lvl=info msg=\"join connections\" obj=join id=b935a18cb0ee l=127.0.0.1:11434 r=160.202.37.200:50923\n",
            "[GIN] 2024/09/19 - 22:01:00 | 200 |   442.40221ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:01+0000 lvl=info msg=\"join connections\" obj=join id=41ce212f0d67 l=127.0.0.1:11434 r=160.202.37.200:50924\n",
            "[GIN] 2024/09/19 - 22:01:01 | 200 |  197.641715ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:02+0000 lvl=info msg=\"join connections\" obj=join id=c0c5c9dabc0e l=127.0.0.1:11434 r=160.202.37.200:50925\n",
            "[GIN] 2024/09/19 - 22:01:03 | 200 |  398.146277ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:04+0000 lvl=info msg=\"join connections\" obj=join id=f15a1ee63bf5 l=127.0.0.1:11434 r=160.202.37.200:50926\n",
            "[GIN] 2024/09/19 - 22:01:04 | 200 |  414.076852ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:05+0000 lvl=info msg=\"join connections\" obj=join id=8110b2f36230 l=127.0.0.1:11434 r=160.202.37.200:50927\n",
            "[GIN] 2024/09/19 - 22:01:06 | 200 |  368.399209ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:07+0000 lvl=info msg=\"join connections\" obj=join id=e1900d9af07f l=127.0.0.1:11434 r=160.202.37.200:50928\n",
            "[GIN] 2024/09/19 - 22:01:07 | 200 |  236.150255ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:09+0000 lvl=info msg=\"join connections\" obj=join id=85a8119902ab l=127.0.0.1:11434 r=160.202.37.200:50929\n",
            "[GIN] 2024/09/19 - 22:01:09 | 200 |  357.733951ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:10+0000 lvl=info msg=\"join connections\" obj=join id=197365ec4754 l=127.0.0.1:11434 r=160.202.37.200:50930\n",
            "[GIN] 2024/09/19 - 22:01:11 | 200 |  393.253924ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:12+0000 lvl=info msg=\"join connections\" obj=join id=3cb62250f404 l=127.0.0.1:11434 r=160.202.37.200:50931\n",
            "[GIN] 2024/09/19 - 22:01:12 | 200 |  391.831589ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:13+0000 lvl=info msg=\"join connections\" obj=join id=14eee4d3961d l=127.0.0.1:11434 r=160.202.37.200:50933\n",
            "[GIN] 2024/09/19 - 22:01:14 | 200 |  458.824644ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:15+0000 lvl=info msg=\"join connections\" obj=join id=d1ed7c25117f l=127.0.0.1:11434 r=160.202.37.200:50934\n",
            "[GIN] 2024/09/19 - 22:01:15 | 200 |  408.662074ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:17+0000 lvl=info msg=\"join connections\" obj=join id=cb351e546660 l=127.0.0.1:11434 r=160.202.37.200:50935\n",
            "[GIN] 2024/09/19 - 22:01:17 | 200 |  336.319871ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:18+0000 lvl=info msg=\"join connections\" obj=join id=da850962a79f l=127.0.0.1:11434 r=160.202.37.200:50936\n",
            "[GIN] 2024/09/19 - 22:01:18 | 200 |  136.916017ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:20+0000 lvl=info msg=\"join connections\" obj=join id=8d1ece36c1ae l=127.0.0.1:11434 r=160.202.37.200:50937\n",
            "[GIN] 2024/09/19 - 22:01:20 | 200 |  276.943162ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:21+0000 lvl=info msg=\"join connections\" obj=join id=4ec77237771f l=127.0.0.1:11434 r=160.202.37.200:50938\n",
            "[GIN] 2024/09/19 - 22:01:21 | 200 |  324.673209ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:23+0000 lvl=info msg=\"join connections\" obj=join id=567b4d25550c l=127.0.0.1:11434 r=160.202.37.200:50939\n",
            "[GIN] 2024/09/19 - 22:01:23 | 200 |  409.697649ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:25+0000 lvl=info msg=\"join connections\" obj=join id=a79a90ddf520 l=127.0.0.1:11434 r=160.202.37.200:50940\n",
            "[GIN] 2024/09/19 - 22:01:25 | 200 |  415.151869ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:26+0000 lvl=info msg=\"join connections\" obj=join id=2abbaf04164f l=127.0.0.1:11434 r=160.202.37.200:50941\n",
            "[GIN] 2024/09/19 - 22:01:27 | 200 |  222.439469ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:28+0000 lvl=info msg=\"join connections\" obj=join id=ca09bdf3ec40 l=127.0.0.1:11434 r=160.202.37.200:50942\n",
            "[GIN] 2024/09/19 - 22:01:28 | 200 |  364.380128ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:30+0000 lvl=info msg=\"join connections\" obj=join id=c9c7a3d93d53 l=127.0.0.1:11434 r=160.202.37.200:50943\n",
            "[GIN] 2024/09/19 - 22:01:30 | 200 |  323.689338ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:31+0000 lvl=info msg=\"join connections\" obj=join id=84d12a77868c l=127.0.0.1:11434 r=160.202.37.200:50944\n",
            "[GIN] 2024/09/19 - 22:01:32 | 200 |  572.268502ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:34+0000 lvl=info msg=\"join connections\" obj=join id=53fa674758db l=127.0.0.1:11434 r=160.202.37.200:50945\n",
            "[GIN] 2024/09/19 - 22:01:34 | 200 |  155.387549ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:35+0000 lvl=info msg=\"join connections\" obj=join id=7ffb3ea61fcc l=127.0.0.1:11434 r=160.202.37.200:50946\n",
            "[GIN] 2024/09/19 - 22:01:35 | 200 |  316.962328ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:37+0000 lvl=info msg=\"join connections\" obj=join id=1897e74c8cd3 l=127.0.0.1:11434 r=160.202.37.200:50947\n",
            "[GIN] 2024/09/19 - 22:01:37 | 200 |  332.490459ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:38+0000 lvl=info msg=\"join connections\" obj=join id=26e77820aa50 l=127.0.0.1:11434 r=160.202.37.200:50948\n",
            "[GIN] 2024/09/19 - 22:01:39 | 200 |   302.53176ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:40+0000 lvl=info msg=\"join connections\" obj=join id=cafce6c32b80 l=127.0.0.1:11434 r=160.202.37.200:50949\n",
            "[GIN] 2024/09/19 - 22:01:41 | 200 |   412.57959ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:42+0000 lvl=info msg=\"join connections\" obj=join id=7ca76f836805 l=127.0.0.1:11434 r=160.202.37.200:50950\n",
            "[GIN] 2024/09/19 - 22:01:42 | 200 |  100.819841ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:43+0000 lvl=info msg=\"join connections\" obj=join id=4a2c23f31711 l=127.0.0.1:11434 r=160.202.37.200:50951\n",
            "[GIN] 2024/09/19 - 22:01:44 | 200 |  419.645509ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:45+0000 lvl=info msg=\"join connections\" obj=join id=f0a2e65dbce2 l=127.0.0.1:11434 r=160.202.37.200:50952\n",
            "[GIN] 2024/09/19 - 22:01:45 | 200 |   340.30528ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:47+0000 lvl=info msg=\"join connections\" obj=join id=7eecda269f9c l=127.0.0.1:11434 r=160.202.37.200:50953\n",
            "[GIN] 2024/09/19 - 22:01:47 | 200 |  299.432944ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:48+0000 lvl=info msg=\"join connections\" obj=join id=5ee0b3c236e6 l=127.0.0.1:11434 r=160.202.37.200:50954\n",
            "[GIN] 2024/09/19 - 22:01:49 | 200 |  432.362636ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:50+0000 lvl=info msg=\"join connections\" obj=join id=a1889a056f95 l=127.0.0.1:11434 r=160.202.37.200:50955\n",
            "[GIN] 2024/09/19 - 22:01:50 | 200 |    87.28734ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:52+0000 lvl=info msg=\"join connections\" obj=join id=6eae5b51eab6 l=127.0.0.1:11434 r=160.202.37.200:50956\n",
            "[GIN] 2024/09/19 - 22:01:52 | 200 |  467.547164ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:54+0000 lvl=info msg=\"join connections\" obj=join id=e2b70749d7bc l=127.0.0.1:11434 r=160.202.37.200:50957\n",
            "[GIN] 2024/09/19 - 22:01:54 | 200 |  358.451975ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:55+0000 lvl=info msg=\"join connections\" obj=join id=8cf946a90202 l=127.0.0.1:11434 r=160.202.37.200:50958\n",
            "[GIN] 2024/09/19 - 22:01:56 | 200 |  318.144557ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:57+0000 lvl=info msg=\"join connections\" obj=join id=2fe5b806a483 l=127.0.0.1:11434 r=160.202.37.200:50959\n",
            "[GIN] 2024/09/19 - 22:01:57 | 200 |  384.490334ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:01:59+0000 lvl=info msg=\"join connections\" obj=join id=c272705a5a00 l=127.0.0.1:11434 r=160.202.37.200:50960\n",
            "[GIN] 2024/09/19 - 22:01:59 | 200 |  394.554515ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:01+0000 lvl=info msg=\"join connections\" obj=join id=76acf22f21c8 l=127.0.0.1:11434 r=160.202.37.200:50961\n",
            "[GIN] 2024/09/19 - 22:02:01 | 200 |  344.091087ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:02+0000 lvl=info msg=\"join connections\" obj=join id=1f201059c5f8 l=127.0.0.1:11434 r=160.202.37.200:50962\n",
            "[GIN] 2024/09/19 - 22:02:03 | 200 |  514.980418ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:04+0000 lvl=info msg=\"join connections\" obj=join id=c5724bd115d0 l=127.0.0.1:11434 r=160.202.37.200:50963\n",
            "[GIN] 2024/09/19 - 22:02:05 | 200 |   226.85138ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:06+0000 lvl=info msg=\"join connections\" obj=join id=8642d4b0f2ae l=127.0.0.1:11434 r=160.202.37.200:50964\n",
            "[GIN] 2024/09/19 - 22:02:07 | 200 |  485.968411ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:08+0000 lvl=info msg=\"join connections\" obj=join id=0a861a0a6850 l=127.0.0.1:11434 r=160.202.37.200:50965\n",
            "[GIN] 2024/09/19 - 22:02:08 | 200 |  341.852212ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:10+0000 lvl=info msg=\"join connections\" obj=join id=5b1b4e21944f l=127.0.0.1:11434 r=160.202.37.200:50966\n",
            "[GIN] 2024/09/19 - 22:02:10 | 200 |  335.995823ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:12+0000 lvl=info msg=\"join connections\" obj=join id=44e2e8b6f8d1 l=127.0.0.1:11434 r=160.202.37.200:50967\n",
            "[GIN] 2024/09/19 - 22:02:12 | 200 |  330.216256ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:13+0000 lvl=info msg=\"join connections\" obj=join id=29c33ab6e44a l=127.0.0.1:11434 r=160.202.37.200:50968\n",
            "[GIN] 2024/09/19 - 22:02:14 | 200 |    80.77728ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:15+0000 lvl=info msg=\"join connections\" obj=join id=9d9471dc4a50 l=127.0.0.1:11434 r=160.202.37.200:50969\n",
            "[GIN] 2024/09/19 - 22:02:15 | 200 |  490.676246ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:17+0000 lvl=info msg=\"join connections\" obj=join id=c8d6afd90a38 l=127.0.0.1:11434 r=160.202.37.200:50970\n",
            "[GIN] 2024/09/19 - 22:02:17 | 200 |  334.418585ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:19+0000 lvl=info msg=\"join connections\" obj=join id=22e0589435a7 l=127.0.0.1:11434 r=160.202.37.200:50971\n",
            "[GIN] 2024/09/19 - 22:02:19 | 200 |  338.192544ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:21+0000 lvl=info msg=\"join connections\" obj=join id=cb2745fa9386 l=127.0.0.1:11434 r=160.202.37.200:50972\n",
            "[GIN] 2024/09/19 - 22:02:21 | 200 |  339.104775ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:22+0000 lvl=info msg=\"join connections\" obj=join id=60d6cfaa383e l=127.0.0.1:11434 r=160.202.37.200:50973\n",
            "[GIN] 2024/09/19 - 22:02:23 | 200 |   69.891133ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:24+0000 lvl=info msg=\"join connections\" obj=join id=e109d0c2fa68 l=127.0.0.1:11434 r=160.202.37.200:50974\n",
            "[GIN] 2024/09/19 - 22:02:25 | 200 |   522.59366ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:26+0000 lvl=info msg=\"join connections\" obj=join id=0da5cf7b3303 l=127.0.0.1:11434 r=160.202.37.200:50975\n",
            "[GIN] 2024/09/19 - 22:02:27 | 200 |    442.5234ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:28+0000 lvl=info msg=\"join connections\" obj=join id=e80f4c89d6a1 l=127.0.0.1:11434 r=160.202.37.200:50976\n",
            "[GIN] 2024/09/19 - 22:02:28 | 200 |   404.30814ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:30+0000 lvl=info msg=\"join connections\" obj=join id=c597fb8bf36f l=127.0.0.1:11434 r=160.202.37.200:50977\n",
            "[GIN] 2024/09/19 - 22:02:30 | 200 |  234.913579ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:02:32+0000 lvl=info msg=\"join connections\" obj=join id=b9bb3f23a597 l=127.0.0.1:11434 r=160.202.37.200:50978\n",
            "[GIN] 2024/09/19 - 22:02:32 | 200 |  321.906033ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:03:08+0000 lvl=info msg=\"join connections\" obj=join id=d55f0a3e8f40 l=127.0.0.1:11434 r=160.202.37.200:50981\n",
            "[GIN] 2024/09/19 - 22:03:08 | 200 |  109.934785ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:03:10+0000 lvl=info msg=\"join connections\" obj=join id=0b9fc8815a27 l=127.0.0.1:11434 r=160.202.37.200:50982\n",
            "[GIN] 2024/09/19 - 22:03:22 | 200 | 11.806946734s |  160.202.37.200 | POST     \"/api/generate\"\n",
            "t=2024-09-19T22:17:00+0000 lvl=info msg=\"join connections\" obj=join id=cfccc38a7c9a l=127.0.0.1:11434 r=160.202.37.200:51383\n",
            "time=2024-09-19T22:17:00.298Z level=INFO source=sched.go:714 msg=\"new model will fit in available VRAM in single GPU, loading\" model=/root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 gpu=GPU-ccd7e713-5603-b5ab-34f0-3c2f4efe8f7f parallel=4 available=15727656960 required=\"8.7 GiB\"\n",
            "time=2024-09-19T22:17:00.298Z level=INFO source=server.go:103 msg=\"system memory\" total=\"12.7 GiB\" free=\"11.3 GiB\" free_swap=\"0 B\"\n",
            "time=2024-09-19T22:17:00.299Z level=INFO source=memory.go:326 msg=\"offload to cuda\" layers.requested=-1 layers.model=33 layers.offload=33 layers.split=\"\" memory.available=\"[14.6 GiB]\" memory.gpu_overhead=\"0 B\" memory.required.full=\"8.7 GiB\" memory.required.partial=\"8.7 GiB\" memory.required.kv=\"4.0 GiB\" memory.required.allocations=\"[8.7 GiB]\" memory.weights.total=\"7.4 GiB\" memory.weights.repeating=\"7.3 GiB\" memory.weights.nonrepeating=\"102.6 MiB\" memory.graph.full=\"560.0 MiB\" memory.graph.partial=\"681.0 MiB\"\n",
            "time=2024-09-19T22:17:00.302Z level=INFO source=server.go:388 msg=\"starting llama server\" cmd=\"/tmp/ollama3690793497/runners/cuda_v12/ollama_llama_server --model /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 --ctx-size 8192 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 4 --port 46525\"\n",
            "time=2024-09-19T22:17:00.303Z level=INFO source=sched.go:449 msg=\"loaded runners\" count=1\n",
            "time=2024-09-19T22:17:00.303Z level=INFO source=server.go:587 msg=\"waiting for llama runner to start responding\"\n",
            "time=2024-09-19T22:17:00.304Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server error\"\n",
            "INFO [main] build info | build=10 commit=\"9225b05\" tid=\"136300039454720\" timestamp=1726784220\n",
            "INFO [main] system info | n_threads=1 n_threads_batch=1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"136300039454720\" timestamp=1726784220 total_threads=2\n",
            "INFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"6\" port=\"46525\" tid=\"136300039454720\" timestamp=1726784220\n",
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,61249]   = [\"▁ t\", \"e r\", \"i n\", \"▁ a\", \"e n...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW)\n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
            "time=2024-09-19T22:17:00.734Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server loading model\"\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  3577.56 MiB\n",
            "llama_new_context_with_model: n_ctx      = 8192\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  4096.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.55 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "INFO [main] model loaded | tid=\"136300039454720\" timestamp=1726784221\n",
            "time=2024-09-19T22:17:01.990Z level=INFO source=server.go:626 msg=\"llama runner started in 1.69 seconds\"\n",
            "[GIN] 2024/09/19 - 22:17:02 | 200 |  1.922100754s |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:17:03+0000 lvl=info msg=\"join connections\" obj=join id=419a581465b8 l=127.0.0.1:11434 r=160.202.37.200:51384\n",
            "[GIN] 2024/09/19 - 22:17:14 | 200 | 10.471592478s |  160.202.37.200 | POST     \"/api/generate\"\n",
            "t=2024-09-19T22:17:46+0000 lvl=info msg=\"join connections\" obj=join id=868fc123804f l=127.0.0.1:11434 r=160.202.37.200:51410\n",
            "[GIN] 2024/09/19 - 22:17:46 | 200 |  131.870376ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:17:48+0000 lvl=info msg=\"join connections\" obj=join id=3972f57c38f1 l=127.0.0.1:11434 r=160.202.37.200:51411\n",
            "[GIN] 2024/09/19 - 22:18:00 | 200 | 12.203073895s |  160.202.37.200 | POST     \"/api/generate\"\n",
            "t=2024-09-19T22:27:59+0000 lvl=info msg=\"join connections\" obj=join id=729b7b47dbaf l=127.0.0.1:11434 r=160.202.37.200:51540\n",
            "time=2024-09-19T22:28:00.114Z level=INFO source=sched.go:714 msg=\"new model will fit in available VRAM in single GPU, loading\" model=/root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 gpu=GPU-ccd7e713-5603-b5ab-34f0-3c2f4efe8f7f parallel=4 available=15727656960 required=\"8.7 GiB\"\n",
            "time=2024-09-19T22:28:00.114Z level=INFO source=server.go:103 msg=\"system memory\" total=\"12.7 GiB\" free=\"11.3 GiB\" free_swap=\"0 B\"\n",
            "time=2024-09-19T22:28:00.115Z level=INFO source=memory.go:326 msg=\"offload to cuda\" layers.requested=-1 layers.model=33 layers.offload=33 layers.split=\"\" memory.available=\"[14.6 GiB]\" memory.gpu_overhead=\"0 B\" memory.required.full=\"8.7 GiB\" memory.required.partial=\"8.7 GiB\" memory.required.kv=\"4.0 GiB\" memory.required.allocations=\"[8.7 GiB]\" memory.weights.total=\"7.4 GiB\" memory.weights.repeating=\"7.3 GiB\" memory.weights.nonrepeating=\"102.6 MiB\" memory.graph.full=\"560.0 MiB\" memory.graph.partial=\"681.0 MiB\"\n",
            "time=2024-09-19T22:28:00.118Z level=INFO source=server.go:388 msg=\"starting llama server\" cmd=\"/tmp/ollama3690793497/runners/cuda_v12/ollama_llama_server --model /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 --ctx-size 8192 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 4 --port 39645\"\n",
            "time=2024-09-19T22:28:00.119Z level=INFO source=sched.go:449 msg=\"loaded runners\" count=1\n",
            "time=2024-09-19T22:28:00.119Z level=INFO source=server.go:587 msg=\"waiting for llama runner to start responding\"\n",
            "time=2024-09-19T22:28:00.119Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server error\"\n",
            "INFO [main] build info | build=10 commit=\"9225b05\" tid=\"132615588745216\" timestamp=1726784880\n",
            "INFO [main] system info | n_threads=1 n_threads_batch=1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"132615588745216\" timestamp=1726784880 total_threads=2\n",
            "INFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"6\" port=\"39645\" tid=\"132615588745216\" timestamp=1726784880\n",
            "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,61249]   = [\"▁ t\", \"e r\", \"i n\", \"▁ a\", \"e n...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
            "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW)\n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
            "time=2024-09-19T22:28:00.548Z level=INFO source=server.go:621 msg=\"waiting for server to become available\" status=\"llm server loading model\"\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  3577.56 MiB\n",
            "llama_new_context_with_model: n_ctx      = 8192\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  4096.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.55 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "INFO [main] model loaded | tid=\"132615588745216\" timestamp=1726784881\n",
            "time=2024-09-19T22:28:01.803Z level=INFO source=server.go:626 msg=\"llama runner started in 1.68 seconds\"\n",
            "[GIN] 2024/09/19 - 22:28:02 | 200 |  2.202791854s |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:03+0000 lvl=info msg=\"join connections\" obj=join id=a82f62730b09 l=127.0.0.1:11434 r=160.202.37.200:51541\n",
            "[GIN] 2024/09/19 - 22:28:03 | 200 |  244.566896ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:05+0000 lvl=info msg=\"join connections\" obj=join id=8e74f6b2a87e l=127.0.0.1:11434 r=160.202.37.200:51542\n",
            "[GIN] 2024/09/19 - 22:28:05 | 200 |  223.321492ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:07+0000 lvl=info msg=\"join connections\" obj=join id=f30fefab8b15 l=127.0.0.1:11434 r=160.202.37.200:51543\n",
            "[GIN] 2024/09/19 - 22:28:07 | 200 |   181.32766ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:08+0000 lvl=info msg=\"join connections\" obj=join id=2455edd3ebbf l=127.0.0.1:11434 r=160.202.37.200:51544\n",
            "[GIN] 2024/09/19 - 22:28:08 | 200 |  264.013118ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:10+0000 lvl=info msg=\"join connections\" obj=join id=6dfc3d7a8d31 l=127.0.0.1:11434 r=160.202.37.200:51545\n",
            "[GIN] 2024/09/19 - 22:28:10 | 200 |  226.277988ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:11+0000 lvl=info msg=\"join connections\" obj=join id=3743249a5c59 l=127.0.0.1:11434 r=160.202.37.200:51546\n",
            "[GIN] 2024/09/19 - 22:28:12 | 200 |  224.585495ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:13+0000 lvl=info msg=\"join connections\" obj=join id=134337cc078e l=127.0.0.1:11434 r=160.202.37.200:51547\n",
            "[GIN] 2024/09/19 - 22:28:13 | 200 |  184.518425ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:14+0000 lvl=info msg=\"join connections\" obj=join id=15ea4a6a4cd0 l=127.0.0.1:11434 r=160.202.37.200:51548\n",
            "[GIN] 2024/09/19 - 22:28:15 | 200 |  210.369432ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:16+0000 lvl=info msg=\"join connections\" obj=join id=42d36cd634c4 l=127.0.0.1:11434 r=160.202.37.200:51549\n",
            "[GIN] 2024/09/19 - 22:28:16 | 200 |  271.090453ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:18+0000 lvl=info msg=\"join connections\" obj=join id=e9118554fce0 l=127.0.0.1:11434 r=160.202.37.200:51550\n",
            "[GIN] 2024/09/19 - 22:28:18 | 200 |  245.370554ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:19+0000 lvl=info msg=\"join connections\" obj=join id=0caed804109a l=127.0.0.1:11434 r=160.202.37.200:51551\n",
            "[GIN] 2024/09/19 - 22:28:19 | 200 |  183.986977ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:21+0000 lvl=info msg=\"join connections\" obj=join id=7b8bcbafe77b l=127.0.0.1:11434 r=160.202.37.200:51552\n",
            "[GIN] 2024/09/19 - 22:28:21 | 200 |  186.843586ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:22+0000 lvl=info msg=\"join connections\" obj=join id=a59302035051 l=127.0.0.1:11434 r=160.202.37.200:51553\n",
            "[GIN] 2024/09/19 - 22:28:22 | 200 |  286.138045ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:23+0000 lvl=info msg=\"join connections\" obj=join id=c6596d158db9 l=127.0.0.1:11434 r=160.202.37.200:51554\n",
            "[GIN] 2024/09/19 - 22:28:24 | 200 |  284.197976ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:25+0000 lvl=info msg=\"join connections\" obj=join id=22ca5d52c2d8 l=127.0.0.1:11434 r=160.202.37.200:51556\n",
            "[GIN] 2024/09/19 - 22:28:25 | 200 |  244.667595ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:26+0000 lvl=info msg=\"join connections\" obj=join id=abadb95c1d23 l=127.0.0.1:11434 r=160.202.37.200:51557\n",
            "[GIN] 2024/09/19 - 22:28:26 | 200 |  116.986006ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:28+0000 lvl=info msg=\"join connections\" obj=join id=0f74a4e09a8a l=127.0.0.1:11434 r=160.202.37.200:51558\n",
            "[GIN] 2024/09/19 - 22:28:28 | 200 |  396.499902ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:30+0000 lvl=info msg=\"join connections\" obj=join id=bebc01716060 l=127.0.0.1:11434 r=160.202.37.200:51559\n",
            "[GIN] 2024/09/19 - 22:28:30 | 200 |  271.996389ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:31+0000 lvl=info msg=\"join connections\" obj=join id=5636adf5887d l=127.0.0.1:11434 r=160.202.37.200:51560\n",
            "[GIN] 2024/09/19 - 22:28:31 | 200 |  288.489173ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:33+0000 lvl=info msg=\"join connections\" obj=join id=23541d65145d l=127.0.0.1:11434 r=160.202.37.200:51561\n",
            "[GIN] 2024/09/19 - 22:28:33 | 200 |  152.209299ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:34+0000 lvl=info msg=\"join connections\" obj=join id=28d5aa2cc7e3 l=127.0.0.1:11434 r=160.202.37.200:51563\n",
            "[GIN] 2024/09/19 - 22:28:35 | 200 |    245.9971ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:36+0000 lvl=info msg=\"join connections\" obj=join id=895315b58686 l=127.0.0.1:11434 r=160.202.37.200:51564\n",
            "[GIN] 2024/09/19 - 22:28:36 | 200 |  245.150119ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:37+0000 lvl=info msg=\"join connections\" obj=join id=3875a0875ccd l=127.0.0.1:11434 r=160.202.37.200:51565\n",
            "[GIN] 2024/09/19 - 22:28:38 | 200 |  297.331197ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:39+0000 lvl=info msg=\"join connections\" obj=join id=98622a0051b1 l=127.0.0.1:11434 r=160.202.37.200:51566\n",
            "[GIN] 2024/09/19 - 22:28:39 | 200 |  192.214856ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:41+0000 lvl=info msg=\"join connections\" obj=join id=35bfe9f79c58 l=127.0.0.1:11434 r=160.202.37.200:51567\n",
            "[GIN] 2024/09/19 - 22:28:41 | 200 |   459.23306ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:43+0000 lvl=info msg=\"join connections\" obj=join id=989055b29e97 l=127.0.0.1:11434 r=160.202.37.200:51568\n",
            "[GIN] 2024/09/19 - 22:28:43 | 200 |  332.800303ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:44+0000 lvl=info msg=\"join connections\" obj=join id=a48cd5c780fe l=127.0.0.1:11434 r=160.202.37.200:51569\n",
            "[GIN] 2024/09/19 - 22:28:45 | 200 |  249.728157ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:46+0000 lvl=info msg=\"join connections\" obj=join id=cc6af2e17d2a l=127.0.0.1:11434 r=160.202.37.200:51570\n",
            "[GIN] 2024/09/19 - 22:28:46 | 200 |   93.056162ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:47+0000 lvl=info msg=\"join connections\" obj=join id=3f67fa767d8a l=127.0.0.1:11434 r=160.202.37.200:51571\n",
            "[GIN] 2024/09/19 - 22:28:48 | 200 |  672.353068ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:49+0000 lvl=info msg=\"join connections\" obj=join id=979ab39d40c2 l=127.0.0.1:11434 r=160.202.37.200:51572\n",
            "[GIN] 2024/09/19 - 22:28:50 | 200 |  247.856144ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:51+0000 lvl=info msg=\"join connections\" obj=join id=2129283580e7 l=127.0.0.1:11434 r=160.202.37.200:51576\n",
            "[GIN] 2024/09/19 - 22:28:51 | 200 |  249.116582ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:53+0000 lvl=info msg=\"join connections\" obj=join id=fc4844a38974 l=127.0.0.1:11434 r=160.202.37.200:51578\n",
            "[GIN] 2024/09/19 - 22:28:53 | 200 |  110.365695ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:55+0000 lvl=info msg=\"join connections\" obj=join id=b71492a2f72a l=127.0.0.1:11434 r=160.202.37.200:51579\n",
            "[GIN] 2024/09/19 - 22:28:55 | 200 |  449.468407ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:57+0000 lvl=info msg=\"join connections\" obj=join id=25da6c21b722 l=127.0.0.1:11434 r=160.202.37.200:51590\n",
            "[GIN] 2024/09/19 - 22:28:57 | 200 |  288.711084ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:28:58+0000 lvl=info msg=\"join connections\" obj=join id=744de2d9f091 l=127.0.0.1:11434 r=160.202.37.200:51591\n",
            "[GIN] 2024/09/19 - 22:28:59 | 200 |  339.200361ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:00+0000 lvl=info msg=\"join connections\" obj=join id=2285e04a74b3 l=127.0.0.1:11434 r=160.202.37.200:51592\n",
            "[GIN] 2024/09/19 - 22:29:00 | 200 |   74.273445ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:02+0000 lvl=info msg=\"join connections\" obj=join id=60da57cf955d l=127.0.0.1:11434 r=160.202.37.200:51593\n",
            "[GIN] 2024/09/19 - 22:29:02 | 200 |  480.371818ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:04+0000 lvl=info msg=\"join connections\" obj=join id=3f930aaea5d6 l=127.0.0.1:11434 r=160.202.37.200:51594\n",
            "[GIN] 2024/09/19 - 22:29:04 | 200 |  355.806431ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:06+0000 lvl=info msg=\"join connections\" obj=join id=d48314189988 l=127.0.0.1:11434 r=160.202.37.200:51595\n",
            "[GIN] 2024/09/19 - 22:29:06 | 200 |  437.623554ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:08+0000 lvl=info msg=\"join connections\" obj=join id=6af4b62d350e l=127.0.0.1:11434 r=160.202.37.200:51596\n",
            "[GIN] 2024/09/19 - 22:29:08 | 200 |  188.054276ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:09+0000 lvl=info msg=\"join connections\" obj=join id=332c373c1298 l=127.0.0.1:11434 r=160.202.37.200:51605\n",
            "[GIN] 2024/09/19 - 22:29:10 | 200 |  374.204304ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:11+0000 lvl=info msg=\"join connections\" obj=join id=2c50f1551e6b l=127.0.0.1:11434 r=160.202.37.200:51609\n",
            "[GIN] 2024/09/19 - 22:29:12 | 200 |    382.4291ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:13+0000 lvl=info msg=\"join connections\" obj=join id=39ae115b2045 l=127.0.0.1:11434 r=160.202.37.200:51615\n",
            "[GIN] 2024/09/19 - 22:29:13 | 200 |  340.507123ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:14+0000 lvl=info msg=\"join connections\" obj=join id=2fc20cbb2124 l=127.0.0.1:11434 r=160.202.37.200:51621\n",
            "[GIN] 2024/09/19 - 22:29:14 | 200 |  224.485605ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:16+0000 lvl=info msg=\"join connections\" obj=join id=5af3b744bc53 l=127.0.0.1:11434 r=160.202.37.200:51628\n",
            "[GIN] 2024/09/19 - 22:29:16 | 200 |   337.58046ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:17+0000 lvl=info msg=\"join connections\" obj=join id=58f7f7cc10b8 l=127.0.0.1:11434 r=160.202.37.200:51631\n",
            "[GIN] 2024/09/19 - 22:29:18 | 200 |  372.470746ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:19+0000 lvl=info msg=\"join connections\" obj=join id=224a533ffb11 l=127.0.0.1:11434 r=160.202.37.200:51632\n",
            "[GIN] 2024/09/19 - 22:29:19 | 200 |  370.639104ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:21+0000 lvl=info msg=\"join connections\" obj=join id=d1b8ef17bd19 l=127.0.0.1:11434 r=160.202.37.200:51633\n",
            "[GIN] 2024/09/19 - 22:29:21 | 200 |  298.196635ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:22+0000 lvl=info msg=\"join connections\" obj=join id=3c446c2e7646 l=127.0.0.1:11434 r=160.202.37.200:51634\n",
            "[GIN] 2024/09/19 - 22:29:23 | 200 |    388.9905ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:24+0000 lvl=info msg=\"join connections\" obj=join id=4fe82876dfa1 l=127.0.0.1:11434 r=160.202.37.200:51635\n",
            "[GIN] 2024/09/19 - 22:29:24 | 200 |  326.468838ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:26+0000 lvl=info msg=\"join connections\" obj=join id=b071595a2873 l=127.0.0.1:11434 r=160.202.37.200:51636\n",
            "[GIN] 2024/09/19 - 22:29:26 | 200 |  134.841405ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:27+0000 lvl=info msg=\"join connections\" obj=join id=87347431a6bb l=127.0.0.1:11434 r=160.202.37.200:51639\n",
            "[GIN] 2024/09/19 - 22:29:28 | 200 |  365.515574ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:29+0000 lvl=info msg=\"join connections\" obj=join id=f8b1094e7256 l=127.0.0.1:11434 r=160.202.37.200:51640\n",
            "[GIN] 2024/09/19 - 22:29:29 | 200 |  309.566699ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:31+0000 lvl=info msg=\"join connections\" obj=join id=b04e77e2a1db l=127.0.0.1:11434 r=160.202.37.200:51641\n",
            "[GIN] 2024/09/19 - 22:29:31 | 200 |  385.085074ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:33+0000 lvl=info msg=\"join connections\" obj=join id=4adb65b7d806 l=127.0.0.1:11434 r=160.202.37.200:51642\n",
            "[GIN] 2024/09/19 - 22:29:33 | 200 |  386.597283ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:35+0000 lvl=info msg=\"join connections\" obj=join id=a8fa716068c2 l=127.0.0.1:11434 r=160.202.37.200:51643\n",
            "[GIN] 2024/09/19 - 22:29:35 | 200 |  211.437731ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:36+0000 lvl=info msg=\"join connections\" obj=join id=e27974db37a5 l=127.0.0.1:11434 r=160.202.37.200:51644\n",
            "[GIN] 2024/09/19 - 22:29:36 | 200 |  345.029233ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:38+0000 lvl=info msg=\"join connections\" obj=join id=8972d7850d15 l=127.0.0.1:11434 r=160.202.37.200:51645\n",
            "[GIN] 2024/09/19 - 22:29:38 | 200 |   311.49705ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:40+0000 lvl=info msg=\"join connections\" obj=join id=f7b0ad67ed5d l=127.0.0.1:11434 r=160.202.37.200:51646\n",
            "[GIN] 2024/09/19 - 22:29:40 | 200 |  387.533481ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:41+0000 lvl=info msg=\"join connections\" obj=join id=0162560a0018 l=127.0.0.1:11434 r=160.202.37.200:51647\n",
            "[GIN] 2024/09/19 - 22:29:41 | 200 |  157.705493ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:43+0000 lvl=info msg=\"join connections\" obj=join id=470ca1c844f7 l=127.0.0.1:11434 r=160.202.37.200:51649\n",
            "[GIN] 2024/09/19 - 22:29:43 | 200 |  345.910657ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:44+0000 lvl=info msg=\"join connections\" obj=join id=49c49a92e24d l=127.0.0.1:11434 r=160.202.37.200:51650\n",
            "[GIN] 2024/09/19 - 22:29:45 | 200 |  320.627471ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:46+0000 lvl=info msg=\"join connections\" obj=join id=d8e05f6202da l=127.0.0.1:11434 r=160.202.37.200:51656\n",
            "[GIN] 2024/09/19 - 22:29:46 | 200 |  286.570599ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:47+0000 lvl=info msg=\"join connections\" obj=join id=9228da920d8d l=127.0.0.1:11434 r=160.202.37.200:51659\n",
            "[GIN] 2024/09/19 - 22:29:48 | 200 |  399.620195ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:49+0000 lvl=info msg=\"join connections\" obj=join id=ece0da389542 l=127.0.0.1:11434 r=160.202.37.200:51660\n",
            "[GIN] 2024/09/19 - 22:29:49 | 200 |   96.077371ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:50+0000 lvl=info msg=\"join connections\" obj=join id=13a0f4cfd145 l=127.0.0.1:11434 r=160.202.37.200:51664\n",
            "[GIN] 2024/09/19 - 22:29:51 | 200 |   435.89551ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:52+0000 lvl=info msg=\"join connections\" obj=join id=7742bae51251 l=127.0.0.1:11434 r=160.202.37.200:51665\n",
            "[GIN] 2024/09/19 - 22:29:53 | 200 |  320.742006ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:54+0000 lvl=info msg=\"join connections\" obj=join id=c26033fa5b4d l=127.0.0.1:11434 r=160.202.37.200:51666\n",
            "[GIN] 2024/09/19 - 22:29:54 | 200 |   285.25362ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:55+0000 lvl=info msg=\"join connections\" obj=join id=e3b04b18fdf9 l=127.0.0.1:11434 r=160.202.37.200:51670\n",
            "[GIN] 2024/09/19 - 22:29:56 | 200 |  422.983328ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:57+0000 lvl=info msg=\"join connections\" obj=join id=cc42554e5b12 l=127.0.0.1:11434 r=160.202.37.200:51673\n",
            "[GIN] 2024/09/19 - 22:29:57 | 200 |   85.502088ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:29:59+0000 lvl=info msg=\"join connections\" obj=join id=8ff3280d4a0d l=127.0.0.1:11434 r=160.202.37.200:51677\n",
            "[GIN] 2024/09/19 - 22:29:59 | 200 |  451.333738ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:30:01+0000 lvl=info msg=\"join connections\" obj=join id=00286694ee1d l=127.0.0.1:11434 r=160.202.37.200:51678\n",
            "[GIN] 2024/09/19 - 22:30:01 | 200 |   357.68367ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:30:18+0000 lvl=info msg=\"join connections\" obj=join id=e918608c4e4a l=127.0.0.1:11434 r=160.202.37.200:51688\n",
            "[GIN] 2024/09/19 - 22:30:18 | 200 |  401.001597ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:30:20+0000 lvl=info msg=\"join connections\" obj=join id=2e07a50fc804 l=127.0.0.1:11434 r=160.202.37.200:51689\n",
            "[GIN] 2024/09/19 - 22:30:20 | 200 |  259.440161ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:30:21+0000 lvl=info msg=\"join connections\" obj=join id=e0f8444d2601 l=127.0.0.1:11434 r=160.202.37.200:51690\n",
            "[GIN] 2024/09/19 - 22:30:22 | 200 |  238.383237ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:30:23+0000 lvl=info msg=\"join connections\" obj=join id=ed50148d6874 l=127.0.0.1:11434 r=160.202.37.200:51691\n",
            "[GIN] 2024/09/19 - 22:30:23 | 200 |  204.915633ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:32:33+0000 lvl=info msg=\"join connections\" obj=join id=983a2ff35c03 l=127.0.0.1:11434 r=160.202.37.200:51704\n",
            "[GIN] 2024/09/19 - 22:32:33 | 200 |  402.869548ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:32:35+0000 lvl=info msg=\"join connections\" obj=join id=f7dcb0c99da7 l=127.0.0.1:11434 r=160.202.37.200:51705\n",
            "[GIN] 2024/09/19 - 22:32:35 | 200 |  259.221713ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:32:36+0000 lvl=info msg=\"join connections\" obj=join id=93cdcec73cee l=127.0.0.1:11434 r=160.202.37.200:51706\n",
            "[GIN] 2024/09/19 - 22:32:37 | 200 |  240.742971ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:32:38+0000 lvl=info msg=\"join connections\" obj=join id=2587f329a681 l=127.0.0.1:11434 r=160.202.37.200:51707\n",
            "[GIN] 2024/09/19 - 22:32:38 | 200 |  195.328846ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:33:50+0000 lvl=info msg=\"join connections\" obj=join id=1e6c18e63452 l=127.0.0.1:11434 r=160.202.37.200:51711\n",
            "[GIN] 2024/09/19 - 22:33:51 | 200 |   431.27271ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:33:52+0000 lvl=info msg=\"join connections\" obj=join id=9b6f4d723404 l=127.0.0.1:11434 r=160.202.37.200:51712\n",
            "[GIN] 2024/09/19 - 22:33:53 | 200 |  256.187908ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:33:54+0000 lvl=info msg=\"join connections\" obj=join id=c40b2554fa53 l=127.0.0.1:11434 r=160.202.37.200:51713\n",
            "[GIN] 2024/09/19 - 22:33:55 | 200 |  234.650412ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:33:56+0000 lvl=info msg=\"join connections\" obj=join id=e2a0448b41ae l=127.0.0.1:11434 r=160.202.37.200:51714\n",
            "[GIN] 2024/09/19 - 22:33:56 | 200 |  192.585265ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:33:57+0000 lvl=info msg=\"join connections\" obj=join id=989815a328a6 l=127.0.0.1:11434 r=160.202.37.200:51715\n",
            "[GIN] 2024/09/19 - 22:33:58 | 200 |   275.51049ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:33:59+0000 lvl=info msg=\"join connections\" obj=join id=d033ffe4ef0c l=127.0.0.1:11434 r=160.202.37.200:51716\n",
            "[GIN] 2024/09/19 - 22:33:59 | 200 |  233.229934ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:01+0000 lvl=info msg=\"join connections\" obj=join id=6f505b6de16f l=127.0.0.1:11434 r=160.202.37.200:51717\n",
            "[GIN] 2024/09/19 - 22:34:01 | 200 |  229.808533ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:02+0000 lvl=info msg=\"join connections\" obj=join id=e13d58284307 l=127.0.0.1:11434 r=160.202.37.200:51720\n",
            "[GIN] 2024/09/19 - 22:34:02 | 200 |   182.59269ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:04+0000 lvl=info msg=\"join connections\" obj=join id=0de07e4dc665 l=127.0.0.1:11434 r=160.202.37.200:51721\n",
            "[GIN] 2024/09/19 - 22:34:04 | 200 |  208.664763ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:05+0000 lvl=info msg=\"join connections\" obj=join id=a45eb912b661 l=127.0.0.1:11434 r=160.202.37.200:51722\n",
            "[GIN] 2024/09/19 - 22:34:05 | 200 |  272.364987ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:07+0000 lvl=info msg=\"join connections\" obj=join id=2bb22c880a7b l=127.0.0.1:11434 r=160.202.37.200:51723\n",
            "[GIN] 2024/09/19 - 22:34:07 | 200 |  251.589858ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:08+0000 lvl=info msg=\"join connections\" obj=join id=533569f56e85 l=127.0.0.1:11434 r=160.202.37.200:51724\n",
            "[GIN] 2024/09/19 - 22:34:08 | 200 |  190.480709ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:10+0000 lvl=info msg=\"join connections\" obj=join id=8f2b00577018 l=127.0.0.1:11434 r=160.202.37.200:51725\n",
            "[GIN] 2024/09/19 - 22:34:10 | 200 |  189.553029ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:11+0000 lvl=info msg=\"join connections\" obj=join id=822aaa431ac9 l=127.0.0.1:11434 r=160.202.37.200:51726\n",
            "[GIN] 2024/09/19 - 22:34:12 | 200 |  303.809019ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:13+0000 lvl=info msg=\"join connections\" obj=join id=6a5008516ea2 l=127.0.0.1:11434 r=160.202.37.200:51727\n",
            "[GIN] 2024/09/19 - 22:34:13 | 200 |  294.216008ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:15+0000 lvl=info msg=\"join connections\" obj=join id=1c7a3cb60c6a l=127.0.0.1:11434 r=160.202.37.200:51728\n",
            "[GIN] 2024/09/19 - 22:34:15 | 200 |  253.292303ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:16+0000 lvl=info msg=\"join connections\" obj=join id=f21eb915cf54 l=127.0.0.1:11434 r=160.202.37.200:51729\n",
            "[GIN] 2024/09/19 - 22:34:16 | 200 |  122.104277ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:18+0000 lvl=info msg=\"join connections\" obj=join id=669dd71df12e l=127.0.0.1:11434 r=160.202.37.200:51730\n",
            "[GIN] 2024/09/19 - 22:34:18 | 200 |   421.51392ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:20+0000 lvl=info msg=\"join connections\" obj=join id=3fb898ca1e4c l=127.0.0.1:11434 r=160.202.37.200:51731\n",
            "[GIN] 2024/09/19 - 22:34:20 | 200 |  279.550825ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:22+0000 lvl=info msg=\"join connections\" obj=join id=8234a1b5d757 l=127.0.0.1:11434 r=160.202.37.200:51732\n",
            "[GIN] 2024/09/19 - 22:34:22 | 200 |  287.504343ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:23+0000 lvl=info msg=\"join connections\" obj=join id=2b9a24ccd7b6 l=127.0.0.1:11434 r=160.202.37.200:51733\n",
            "[GIN] 2024/09/19 - 22:34:24 | 200 |  151.207042ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:25+0000 lvl=info msg=\"join connections\" obj=join id=578b9768a2e8 l=127.0.0.1:11434 r=160.202.37.200:51734\n",
            "[GIN] 2024/09/19 - 22:34:25 | 200 |   245.92135ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:26+0000 lvl=info msg=\"join connections\" obj=join id=208d508119fe l=127.0.0.1:11434 r=160.202.37.200:51735\n",
            "[GIN] 2024/09/19 - 22:34:27 | 200 |  248.700082ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:28+0000 lvl=info msg=\"join connections\" obj=join id=0df266aad737 l=127.0.0.1:11434 r=160.202.37.200:51736\n",
            "[GIN] 2024/09/19 - 22:34:28 | 200 |  304.265568ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:30+0000 lvl=info msg=\"join connections\" obj=join id=6ad62f910c03 l=127.0.0.1:11434 r=160.202.37.200:51737\n",
            "[GIN] 2024/09/19 - 22:34:30 | 200 |  192.195637ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:31+0000 lvl=info msg=\"join connections\" obj=join id=f2cee9dc91ea l=127.0.0.1:11434 r=160.202.37.200:51738\n",
            "[GIN] 2024/09/19 - 22:34:32 | 200 |  476.613295ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:33+0000 lvl=info msg=\"join connections\" obj=join id=3296d211ccb9 l=127.0.0.1:11434 r=160.202.37.200:51739\n",
            "[GIN] 2024/09/19 - 22:34:33 | 200 |  342.686955ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:35+0000 lvl=info msg=\"join connections\" obj=join id=ed0a0ff29f17 l=127.0.0.1:11434 r=160.202.37.200:51740\n",
            "[GIN] 2024/09/19 - 22:34:35 | 200 |  263.693963ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:36+0000 lvl=info msg=\"join connections\" obj=join id=40cf515498c9 l=127.0.0.1:11434 r=160.202.37.200:51741\n",
            "[GIN] 2024/09/19 - 22:34:36 | 200 |   95.788226ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:38+0000 lvl=info msg=\"join connections\" obj=join id=23e68bc021a1 l=127.0.0.1:11434 r=160.202.37.200:51742\n",
            "[GIN] 2024/09/19 - 22:34:38 | 200 |  586.742849ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:40+0000 lvl=info msg=\"join connections\" obj=join id=cc8e49686a3e l=127.0.0.1:11434 r=160.202.37.200:51743\n",
            "[GIN] 2024/09/19 - 22:34:40 | 200 |  253.119364ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:42+0000 lvl=info msg=\"join connections\" obj=join id=89d5a3118ff8 l=127.0.0.1:11434 r=160.202.37.200:51744\n",
            "[GIN] 2024/09/19 - 22:34:42 | 200 |  212.670529ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:43+0000 lvl=info msg=\"join connections\" obj=join id=618c48dc5124 l=127.0.0.1:11434 r=160.202.37.200:51745\n",
            "[GIN] 2024/09/19 - 22:34:43 | 200 |  107.202706ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:45+0000 lvl=info msg=\"join connections\" obj=join id=78153acc7378 l=127.0.0.1:11434 r=160.202.37.200:51746\n",
            "[GIN] 2024/09/19 - 22:34:45 | 200 |  492.915258ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:47+0000 lvl=info msg=\"join connections\" obj=join id=7f59c34d9ecc l=127.0.0.1:11434 r=160.202.37.200:51748\n",
            "[GIN] 2024/09/19 - 22:34:47 | 200 |  254.758177ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:49+0000 lvl=info msg=\"join connections\" obj=join id=33563079844a l=127.0.0.1:11434 r=160.202.37.200:51750\n",
            "[GIN] 2024/09/19 - 22:34:49 | 200 |  349.665783ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:51+0000 lvl=info msg=\"join connections\" obj=join id=699963550033 l=127.0.0.1:11434 r=160.202.37.200:51754\n",
            "[GIN] 2024/09/19 - 22:34:51 | 200 |  125.842303ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:52+0000 lvl=info msg=\"join connections\" obj=join id=443e33daf3e1 l=127.0.0.1:11434 r=160.202.37.200:51755\n",
            "[GIN] 2024/09/19 - 22:34:52 | 200 |  457.343109ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:54+0000 lvl=info msg=\"join connections\" obj=join id=f94c1e121ab2 l=127.0.0.1:11434 r=160.202.37.200:51756\n",
            "[GIN] 2024/09/19 - 22:34:54 | 200 |  345.537962ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:56+0000 lvl=info msg=\"join connections\" obj=join id=a9206d72d885 l=127.0.0.1:11434 r=160.202.37.200:51757\n",
            "[GIN] 2024/09/19 - 22:34:56 | 200 |  423.499295ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:58+0000 lvl=info msg=\"join connections\" obj=join id=3b16f0fa3d7a l=127.0.0.1:11434 r=160.202.37.200:51758\n",
            "[GIN] 2024/09/19 - 22:34:58 | 200 |  187.908413ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:34:59+0000 lvl=info msg=\"join connections\" obj=join id=007cc117c8b2 l=127.0.0.1:11434 r=160.202.37.200:51759\n",
            "[GIN] 2024/09/19 - 22:35:00 | 200 |  379.011601ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:01+0000 lvl=info msg=\"join connections\" obj=join id=b90aa78f3af3 l=127.0.0.1:11434 r=160.202.37.200:51760\n",
            "[GIN] 2024/09/19 - 22:35:02 | 200 |   385.07642ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:03+0000 lvl=info msg=\"join connections\" obj=join id=87f1bd84609b l=127.0.0.1:11434 r=160.202.37.200:51761\n",
            "[GIN] 2024/09/19 - 22:35:03 | 200 |  348.454946ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:04+0000 lvl=info msg=\"join connections\" obj=join id=cc975d5cf4b3 l=127.0.0.1:11434 r=160.202.37.200:51762\n",
            "[GIN] 2024/09/19 - 22:35:04 | 200 |  226.839579ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:06+0000 lvl=info msg=\"join connections\" obj=join id=9ab220ea265d l=127.0.0.1:11434 r=160.202.37.200:51763\n",
            "[GIN] 2024/09/19 - 22:35:06 | 200 |  342.179708ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:07+0000 lvl=info msg=\"join connections\" obj=join id=13b5db5b200a l=127.0.0.1:11434 r=160.202.37.200:51764\n",
            "[GIN] 2024/09/19 - 22:35:08 | 200 |  378.692823ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:09+0000 lvl=info msg=\"join connections\" obj=join id=f232e29838a7 l=127.0.0.1:11434 r=160.202.37.200:51765\n",
            "[GIN] 2024/09/19 - 22:35:10 | 200 |  375.058537ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:11+0000 lvl=info msg=\"join connections\" obj=join id=379837107f66 l=127.0.0.1:11434 r=160.202.37.200:51766\n",
            "[GIN] 2024/09/19 - 22:35:11 | 200 |  307.569588ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:13+0000 lvl=info msg=\"join connections\" obj=join id=f00ce67a7ebb l=127.0.0.1:11434 r=160.202.37.200:51767\n",
            "[GIN] 2024/09/19 - 22:35:13 | 200 |  389.575001ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:14+0000 lvl=info msg=\"join connections\" obj=join id=e9124ba7bb22 l=127.0.0.1:11434 r=160.202.37.200:51768\n",
            "[GIN] 2024/09/19 - 22:35:15 | 200 |  326.069031ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:16+0000 lvl=info msg=\"join connections\" obj=join id=7d5e43db2289 l=127.0.0.1:11434 r=160.202.37.200:51769\n",
            "[GIN] 2024/09/19 - 22:35:16 | 200 |  134.455996ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:17+0000 lvl=info msg=\"join connections\" obj=join id=198d758ab6a0 l=127.0.0.1:11434 r=160.202.37.200:51770\n",
            "[GIN] 2024/09/19 - 22:35:18 | 200 |  251.610296ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:19+0000 lvl=info msg=\"join connections\" obj=join id=a477e68c5867 l=127.0.0.1:11434 r=160.202.37.200:51771\n",
            "[GIN] 2024/09/19 - 22:35:19 | 200 |  304.575771ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:21+0000 lvl=info msg=\"join connections\" obj=join id=738e2f89b6db l=127.0.0.1:11434 r=160.202.37.200:51772\n",
            "[GIN] 2024/09/19 - 22:35:21 | 200 |  381.833167ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:22+0000 lvl=info msg=\"join connections\" obj=join id=f24da9aed886 l=127.0.0.1:11434 r=160.202.37.200:51773\n",
            "[GIN] 2024/09/19 - 22:35:23 | 200 |  379.420156ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:24+0000 lvl=info msg=\"join connections\" obj=join id=5ea812860651 l=127.0.0.1:11434 r=160.202.37.200:51774\n",
            "[GIN] 2024/09/19 - 22:35:24 | 200 |  211.468278ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:25+0000 lvl=info msg=\"join connections\" obj=join id=79abadd6ee9d l=127.0.0.1:11434 r=160.202.37.200:51775\n",
            "[GIN] 2024/09/19 - 22:35:26 | 200 |  344.729782ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:27+0000 lvl=info msg=\"join connections\" obj=join id=9c8fc499466a l=127.0.0.1:11434 r=160.202.37.200:51776\n",
            "[GIN] 2024/09/19 - 22:35:27 | 200 |  302.498173ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:29+0000 lvl=info msg=\"join connections\" obj=join id=9b2a831fdb39 l=127.0.0.1:11434 r=160.202.37.200:51777\n",
            "[GIN] 2024/09/19 - 22:35:29 | 200 |  390.851856ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:31+0000 lvl=info msg=\"join connections\" obj=join id=0590fdd6aa12 l=127.0.0.1:11434 r=160.202.37.200:51778\n",
            "[GIN] 2024/09/19 - 22:35:31 | 200 |  152.532092ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:32+0000 lvl=info msg=\"join connections\" obj=join id=d5648727095a l=127.0.0.1:11434 r=160.202.37.200:51779\n",
            "[GIN] 2024/09/19 - 22:35:33 | 200 |  397.948827ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:34+0000 lvl=info msg=\"join connections\" obj=join id=92f072b81513 l=127.0.0.1:11434 r=160.202.37.200:51780\n",
            "[GIN] 2024/09/19 - 22:35:34 | 200 |  311.113751ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:35+0000 lvl=info msg=\"join connections\" obj=join id=2a205d19ca01 l=127.0.0.1:11434 r=160.202.37.200:51781\n",
            "[GIN] 2024/09/19 - 22:35:36 | 200 |  278.057338ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:37+0000 lvl=info msg=\"join connections\" obj=join id=6473dbb92156 l=127.0.0.1:11434 r=160.202.37.200:51782\n",
            "[GIN] 2024/09/19 - 22:35:37 | 200 |  346.539551ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:38+0000 lvl=info msg=\"join connections\" obj=join id=022515d908c0 l=127.0.0.1:11434 r=160.202.37.200:51783\n",
            "[GIN] 2024/09/19 - 22:35:38 | 200 |   97.790648ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:39+0000 lvl=info msg=\"join connections\" obj=join id=a4eee895945c l=127.0.0.1:11434 r=160.202.37.200:51784\n",
            "[GIN] 2024/09/19 - 22:35:40 | 200 |   417.38538ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:41+0000 lvl=info msg=\"join connections\" obj=join id=d9dd31dd01ce l=127.0.0.1:11434 r=160.202.37.200:51785\n",
            "[GIN] 2024/09/19 - 22:35:42 | 200 |  476.496597ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:43+0000 lvl=info msg=\"join connections\" obj=join id=7e589042f2aa l=127.0.0.1:11434 r=160.202.37.200:51787\n",
            "[GIN] 2024/09/19 - 22:35:43 | 200 |   280.93358ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:45+0000 lvl=info msg=\"join connections\" obj=join id=4a223cfbf28e l=127.0.0.1:11434 r=160.202.37.200:51788\n",
            "[GIN] 2024/09/19 - 22:35:45 | 200 |  418.153746ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:46+0000 lvl=info msg=\"join connections\" obj=join id=8f2861245354 l=127.0.0.1:11434 r=160.202.37.200:51789\n",
            "[GIN] 2024/09/19 - 22:35:46 | 200 |   87.389545ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:48+0000 lvl=info msg=\"join connections\" obj=join id=fd40aa561d32 l=127.0.0.1:11434 r=160.202.37.200:51790\n",
            "[GIN] 2024/09/19 - 22:35:48 | 200 |  451.448754ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:50+0000 lvl=info msg=\"join connections\" obj=join id=ce804d85550d l=127.0.0.1:11434 r=160.202.37.200:51791\n",
            "[GIN] 2024/09/19 - 22:35:50 | 200 |  345.755255ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:52+0000 lvl=info msg=\"join connections\" obj=join id=e48fd7b00b34 l=127.0.0.1:11434 r=160.202.37.200:51792\n",
            "[GIN] 2024/09/19 - 22:35:52 | 200 |  302.717503ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:54+0000 lvl=info msg=\"join connections\" obj=join id=c00ef6103873 l=127.0.0.1:11434 r=160.202.37.200:51794\n",
            "[GIN] 2024/09/19 - 22:35:54 | 200 |  316.925867ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:55+0000 lvl=info msg=\"join connections\" obj=join id=6fc714750162 l=127.0.0.1:11434 r=160.202.37.200:51795\n",
            "[GIN] 2024/09/19 - 22:35:56 | 200 |  373.206337ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:57+0000 lvl=info msg=\"join connections\" obj=join id=19bc3e1a1ea0 l=127.0.0.1:11434 r=160.202.37.200:51796\n",
            "[GIN] 2024/09/19 - 22:35:57 | 200 |   318.98573ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:35:58+0000 lvl=info msg=\"join connections\" obj=join id=ad121943927b l=127.0.0.1:11434 r=160.202.37.200:51797\n",
            "[GIN] 2024/09/19 - 22:35:59 | 200 |  409.359242ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:00+0000 lvl=info msg=\"join connections\" obj=join id=12099a2e6922 l=127.0.0.1:11434 r=160.202.37.200:51798\n",
            "[GIN] 2024/09/19 - 22:36:00 | 200 |  211.002046ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:01+0000 lvl=info msg=\"join connections\" obj=join id=a3bba474a7f4 l=127.0.0.1:11434 r=160.202.37.200:51799\n",
            "[GIN] 2024/09/19 - 22:36:02 | 200 |  460.507113ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:03+0000 lvl=info msg=\"join connections\" obj=join id=3e981c077b7e l=127.0.0.1:11434 r=160.202.37.200:51800\n",
            "[GIN] 2024/09/19 - 22:36:03 | 200 |  325.440903ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:04+0000 lvl=info msg=\"join connections\" obj=join id=d1ecebed0231 l=127.0.0.1:11434 r=160.202.37.200:51801\n",
            "[GIN] 2024/09/19 - 22:36:05 | 200 |  326.688251ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:06+0000 lvl=info msg=\"join connections\" obj=join id=328f43ddbb6b l=127.0.0.1:11434 r=160.202.37.200:51802\n",
            "[GIN] 2024/09/19 - 22:36:07 | 200 |  327.481184ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:08+0000 lvl=info msg=\"join connections\" obj=join id=d6a7d74e44d0 l=127.0.0.1:11434 r=160.202.37.200:51803\n",
            "[GIN] 2024/09/19 - 22:36:08 | 200 |   80.883287ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:09+0000 lvl=info msg=\"join connections\" obj=join id=3cbe00934799 l=127.0.0.1:11434 r=160.202.37.200:51804\n",
            "[GIN] 2024/09/19 - 22:36:10 | 200 |  456.904718ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:11+0000 lvl=info msg=\"join connections\" obj=join id=5cc40597646d l=127.0.0.1:11434 r=160.202.37.200:51805\n",
            "[GIN] 2024/09/19 - 22:36:11 | 200 |  316.362006ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:12+0000 lvl=info msg=\"join connections\" obj=join id=833ae90ebcd3 l=127.0.0.1:11434 r=160.202.37.200:51806\n",
            "[GIN] 2024/09/19 - 22:36:13 | 200 |  314.133152ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:14+0000 lvl=info msg=\"join connections\" obj=join id=5f1722934efe l=127.0.0.1:11434 r=160.202.37.200:51807\n",
            "[GIN] 2024/09/19 - 22:36:14 | 200 |  315.453426ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:16+0000 lvl=info msg=\"join connections\" obj=join id=8b45403c760b l=127.0.0.1:11434 r=160.202.37.200:51808\n",
            "[GIN] 2024/09/19 - 22:36:16 | 200 |   65.188828ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:17+0000 lvl=info msg=\"join connections\" obj=join id=20d1d357e4f8 l=127.0.0.1:11434 r=160.202.37.200:51809\n",
            "[GIN] 2024/09/19 - 22:36:18 | 200 |  509.673509ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:19+0000 lvl=info msg=\"join connections\" obj=join id=efebc5e6e9c4 l=127.0.0.1:11434 r=160.202.37.200:51810\n",
            "[GIN] 2024/09/19 - 22:36:20 | 200 |   421.90179ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:21+0000 lvl=info msg=\"join connections\" obj=join id=2dc1434bd51d l=127.0.0.1:11434 r=160.202.37.200:51811\n",
            "[GIN] 2024/09/19 - 22:36:21 | 200 |  384.342636ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:22+0000 lvl=info msg=\"join connections\" obj=join id=9954121bdffc l=127.0.0.1:11434 r=160.202.37.200:51812\n",
            "[GIN] 2024/09/19 - 22:36:23 | 200 |  273.960789ms |  160.202.37.200 | POST     \"/api/embeddings\"\n",
            "t=2024-09-19T22:36:24+0000 lvl=info msg=\"join connections\" obj=join id=c56bc7af938d l=127.0.0.1:11434 r=160.202.37.200:51813\n",
            "[GIN] 2024/09/19 - 22:36:24 | 200 |   307.88769ms |  160.202.37.200 | POST     \"/api/embeddings\"\n"
          ]
        }
      ],
      "source": [
        "# Run multiple tasks concurrently:\n",
        "#  1. Start the Ollama server.\n",
        "#  2. Start ngrok to forward HTTP traffic from the local ollama api running on localhost:11434.\n",
        "#     Instructions come from Ollama doc: https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-use-ollama-with-ngrok\n",
        "await asyncio.gather(\n",
        "    run(['ollama', 'serve']),\n",
        "\n",
        "    # If you don't want to map to a static URL in Ngrok, uncomment line 9 and comment line 10 before running this cell\n",
        "    # run(['ngrok', 'http', '--log', 'stderr', '11434', '--host-header', 'localhost:11434']),\n",
        "    run(['ngrok', 'http', '--log', 'stderr', '11434', '--host-header', 'localhost:11434', '--domain', DOMAIN]),\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
